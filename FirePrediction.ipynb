{"cells":[{"cell_type":"markdown","metadata":{"id":"SNVOh1QW4eWq"},"source":["# Read data"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"KpebCZ5D4rCN","ExecuteTime":{"end_time":"2024-04-28T05:37:42.863049Z","start_time":"2024-04-28T05:37:39.997263Z"},"executionInfo":{"status":"ok","timestamp":1716473902221,"user_tz":-180,"elapsed":429,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","pd.set_option('display.max_columns', None)\n","import seaborn as sns\n","import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"43aqCciu4sIb","ExecuteTime":{"end_time":"2024-04-28T05:37:48.413993Z","start_time":"2024-04-28T05:37:39.998432Z"},"executionInfo":{"status":"error","timestamp":1716473902222,"user_tz":-180,"elapsed":27,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}},"outputId":"212c5541-42af-48d4-9812-4a23c1e899e6","colab":{"base_uri":"https://localhost:8080/","height":316}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/Projects/FirePrediction/data.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-15ee65c2701a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# replace this with the file path on your computer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Projects/FirePrediction/data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Projects/FirePrediction/data.csv'"]}],"source":["# replace this with the file path on your computer\n","df = pd.read_csv('/content/drive/MyDrive/Projects/FirePrediction/data.csv', index_col=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ftw4OHO7osU","ExecuteTime":{"end_time":"2024-04-28T05:37:48.452369Z","start_time":"2024-04-28T05:37:44.561578Z"},"executionInfo":{"status":"aborted","timestamp":1716473902223,"user_tz":-180,"elapsed":21,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["target_classes = df['STAT_CAUSE_DESCR'].unique()\n","target_classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hqwzGFpeIu2S","ExecuteTime":{"end_time":"2024-04-28T05:37:48.454304Z","start_time":"2024-04-28T05:37:44.622727Z"},"executionInfo":{"status":"aborted","timestamp":1716473902223,"user_tz":-180,"elapsed":20,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["# Generic function that will transform the data into format of XGBoost\n","from sklearn.preprocessing import LabelEncoder\n","target_encoder = LabelEncoder()\n","# initialize target encoder for y to maintain consistency\n","target_encoder.fit(df['STAT_CAUSE_DESCR'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xM80_9VD7pKi","ExecuteTime":{"end_time":"2024-04-28T05:37:48.454521Z","start_time":"2024-04-28T05:37:44.630409Z"},"executionInfo":{"status":"aborted","timestamp":1716473902224,"user_tz":-180,"elapsed":20,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["# train-test-split before I preform anything\n","from sklearn.model_selection import train_test_split\n","X = df.drop(columns='STAT_CAUSE_DESCR')\n","y = df['STAT_CAUSE_DESCR']\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"]},{"cell_type":"markdown","metadata":{"id":"_wrQ3Npg0yZU"},"source":["# Geo Spacial data"]},{"cell_type":"markdown","metadata":{"id":"ukgB6ubwE35N"},"source":["## EDA"]},{"cell_type":"markdown","source":["We can notice that some states have a high amount of incidents where most states have less than or equal to 10k. A big amount of the Debris Burnings happened in Georgia and Texas, states that are characterized with dry and hot climate.\n"],"metadata":{"id":"mCLNZGYuIa_E"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"snJdQnmcE9aj","ExecuteTime":{"end_time":"2024-04-28T05:37:49.552123Z","start_time":"2024-04-28T05:37:46.807177Z"},"executionInfo":{"status":"aborted","timestamp":1716473902224,"user_tz":-180,"elapsed":19,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["# We give color for each cause to see each cause on a map\n","colors = ['red', 'blue','gray','darkred','orange', 'beige','yellow', 'darkgreen','darkblue','purple','pink', 'lightgray','green', 'black']\n","causes = df['STAT_CAUSE_DESCR'].unique()\n","colors_cause_dic = {causes[i]: colors[i] for i in range(len(causes))}\n","fig, ax = plt.subplots(3, 4, figsize=(15, 15))\n","for i, cause in enumerate(colors_cause_dic.keys()):\n","  row = i//4\n","  col = i%4\n","  ax[row, col].scatter(x=df[df['STAT_CAUSE_DESCR'] == cause]['LONGITUDE'],\n","             y=df[df['STAT_CAUSE_DESCR'] == cause]['LATITUDE'],\n","             c=colors_cause_dic[cause], label=cause, s=1)\n","  ax[row, col].set_title(cause)\n","plt.show()"]},{"cell_type":"markdown","source":["Indeed we can see that the Debris Burning is dense at the South and East side of the map where Texas and Georgia are. We can also look at lightning and see a big dense circle at the top left where Alaska is.\n"],"metadata":{"id":"arfz6yGhIgLI"}},{"cell_type":"markdown","source":["We checked the distribution of the labels per state to see if we can detect some anomaly cases"],"metadata":{"id":"1SWJ6CT_IMDm"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hG5DRchEFtbk","ExecuteTime":{"end_time":"2024-04-28T05:37:50.530046Z","start_time":"2024-04-28T05:37:49.094942Z"},"executionInfo":{"status":"aborted","timestamp":1716473902225,"user_tz":-180,"elapsed":20,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Grouping by 'state' and 'target', then counting occurrences\n","grouped = df.groupby(['STATE', 'STAT_CAUSE_DESCR']).size().unstack(fill_value=0)\n","\n","# Calculating percentages\n","grouped_percentage = grouped.div(grouped.sum(axis=1), axis=0) * 100\n","\n","# Plotting stacked bar charts\n","fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 12))\n","\n","# Plotting counts\n","grouped.plot(kind='bar', stacked=True, ax=axes[0])\n","axes[0].set_title('Stacked Bar Chart of Targets by State (Counts)')\n","axes[0].set_xlabel('State')\n","axes[0].set_ylabel('Count')\n","axes[0].legend(title='Target')\n","axes[0].tick_params(axis='x', rotation=90)\n","\n","# Plotting percentages\n","grouped_percentage.plot(kind='bar', stacked=True, ax=axes[1])\n","axes[1].set_title('Stacked Bar Chart of Target Percentages by State')\n","axes[1].set_xlabel('State')\n","axes[1].set_ylabel('Percentage')\n","axes[1].legend(title='Target')\n","axes[1].tick_params(axis='x', rotation=90)\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"9-3St8wMH88L"},"source":["We fix a state, and see how the distribution will change. We use the new distribution to divide by the original distribution to understand how much the fixing of the state influences the prediction of the target classes.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kk2_YQslIC1A","ExecuteTime":{"end_time":"2024-04-28T05:37:51.585649Z","start_time":"2024-04-28T05:37:50.545828Z"},"executionInfo":{"status":"aborted","timestamp":1716473902225,"user_tz":-180,"elapsed":19,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["percentage_of_each_label = df['STAT_CAUSE_DESCR'].value_counts(normalize=True)\n","def plot_big_crosstab_vs_original(df, feature_name, n_rows, n_cols):\n","  # no need input check here: n_rows/cols of the plot, not of dataframe\n","  total_plots = n_rows * n_cols\n","  fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 8))\n","  cross_Vals = pd.crosstab(df[feature_name], df['STAT_CAUSE_DESCR'],  normalize='index')\n","  cross_Vals = cross_Vals.div(percentage_of_each_label, axis=1)\n","  axes = axes.flatten()\n","\n","  for i in range(total_plots):\n","    start_idx = i * len(cross_Vals) // total_plots\n","    end_idx = (i + 1) * len(cross_Vals) // total_plots\n","    subset_df = cross_Vals.iloc[start_idx: end_idx]\n","    sns.heatmap(subset_df, annot=True, annot_kws={\"fontsize\":4}, ax=axes[i])\n","  plt.show()\n","plot_big_crosstab_vs_original(df, 'STATE', 2, 2)"]},{"cell_type":"markdown","metadata":{"id":"bGbUDtNbK0hJ"},"source":["## Feature Engineering"]},{"cell_type":"markdown","metadata":{"id":"J46Qk5cP3ZOV"},"source":["### Longitude and latitude"]},{"cell_type":"markdown","metadata":{"id":"G-fImZ5T3gx4"},"source":["First thing we do, is simply passing in the longitude and latitude to the model, and this increase the result by 0.5 percent.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"XtGBh2UX752p"},"source":["Now we will cluster the points using DBSCAN, and then calculate the distance of each point to it's nearest cluster. (Distance to centroid of the cluster).  We will do this also group by each target class in the target"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t4PnFhMy3dWl","ExecuteTime":{"end_time":"2024-04-28T05:37:51.610056Z","start_time":"2024-04-28T05:37:51.585226Z"},"executionInfo":{"status":"aborted","timestamp":1716473902226,"user_tz":-180,"elapsed":19,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["from sklearn.cluster import DBSCAN\n","\n","target_class_clusters = {}\n","def get_clusters_centroids(df):\n","  epsilon = 0.5  # maximum distance between points to be considered in the same neighborhood\n","  min_samples = 5  # minimum number of points in a neighborhood to be considered a core point\n","  dbscan = DBSCAN(eps=epsilon, min_samples=min_samples)\n","  # now apply DBSCAN\n","  dbscan.fit(df[['LATITUDE', 'LONGITUDE']])\n","  # Get the indices of core samples\n","  core_samples_mask = np.zeros_like(dbscan.labels_, dtype=bool)\n","  core_samples_mask[dbscan.core_sample_indices_] = True\n","  # Get the unique cluster labels\n","  labels = dbscan.labels_\n","  n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n","  # Now Calculate the cluster centroids\n","  clusters_centroids = []\n","  for i in range(n_clusters):\n","      cluster_points = df[['LATITUDE', 'LONGITUDE']][labels == i]\n","      cluster_center = np.mean(cluster_points, axis=0)\n","      clusters_centroids.append(cluster_center)\n","  clusters_centroids = np.array(clusters_centroids)\n","  return clusters_centroids\n","\n","def train_target_class_clusters(df):\n","  for target_class in target_classes:\n","    df_target_class = df[df['STAT_CAUSE_DESCR']== target_class]\n","    target_class_clusters[target_class] = get_clusters_centroids(df_target_class)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wl51csPuEaaj","ExecuteTime":{"end_time":"2024-04-28T05:37:51.610291Z","start_time":"2024-04-28T05:37:51.591122Z"},"executionInfo":{"status":"aborted","timestamp":1716473902226,"user_tz":-180,"elapsed":19,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["def encode_dis_to_nearest_centroid(row, target_class):\n","  clusters_centroids = target_class_clusters[target_class]\n","  point = [row['LATITUDE'], row['LONGITUDE']]\n","  cluster_distances = np.linalg.norm(clusters_centroids - point, axis=1)  # Calculate distances to all centroids at once\n","  min_distance = np.min(cluster_distances)  # Find the minimum distance\n","  return min_distance\n","\n"]},{"cell_type":"markdown","metadata":{"id":"o5CQpokG1NTr"},"source":["### STATE"]},{"cell_type":"markdown","metadata":{"id":"Ww3Tl9kn01-m"},"source":["We encode the state by how much they contribute to predicting the target class. Basically we take the number in the heatmap above, and for each target class, we encode the sample by how much the state this sample is in affects the prediction of the label.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_aOnWtRx14l1","ExecuteTime":{"end_time":"2024-04-28T05:37:51.610458Z","start_time":"2024-04-28T05:37:51.595021Z"},"executionInfo":{"status":"aborted","timestamp":1716473902227,"user_tz":-180,"elapsed":19,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["state_significance = {}\n","\n","def train_state_encoders(df):\n","  # find out for each class which states will have higher than normal percentage of the class instance.\n","  percentage_of_each_label = df['STAT_CAUSE_DESCR'].value_counts(normalize=True)\n","  cross_Vals = pd.crosstab(df['STATE'], df['STAT_CAUSE_DESCR'],  normalize='index')\n","  cross_Vals = cross_Vals.div(percentage_of_each_label, axis=1)\n","\n","  # For each class, we will encode each state to \"how important they are to prediction the class\"\n","  for target_class in target_classes:\n","    state_significance_per_class = {}\n","    for state in cross_Vals.index:\n","      significance = cross_Vals.loc[state, target_class]\n","      state_significance_per_class[state] = significance\n","    state_significance[target_class] = state_significance_per_class\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Hvvfvcvm-AQU"},"source":["Notice here that we could have train one column, comparing whole distribution using kl divergence, but I split it up for each class, hoping that this might provide more insight. Turns out this is a very important approach. All the features generated here are the most important features."]},{"cell_type":"markdown","metadata":{"id":"bGTVsX9OrOgP"},"source":["### COUNTY"]},{"cell_type":"markdown","metadata":{"id":"VPFjxFWnra9p"},"source":["There are some missing values in county. And we can see that county-fip_code-fip_name are being null together.   \n","Also we can see that county being null have a negative influence on powerline and rail road.  \n","So since XGBoost can fill in null values, we passed this feature in as is, and it helped the performance.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eJe25PIVvtza","ExecuteTime":{"end_time":"2024-04-28T05:37:51.610644Z","start_time":"2024-04-28T05:37:51.596578Z"},"executionInfo":{"status":"aborted","timestamp":1716473902227,"user_tz":-180,"elapsed":19,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["def encode_geospacial_data(df):\n","  # encode state\n","  for target_class in target_classes:\n","    df['SE-'+ target_class] = df['STATE'].map(state_significance[target_class])\n","\n","  # encode longitude and latitude\n","  for target_class in target_classes:\n","    df['DISTANCE_TO_CLUSTERS-'+target_class] = df.apply(encode_dis_to_nearest_centroid,args=(target_class,), axis=1)\n","  return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JYyKCrtd4tGP","ExecuteTime":{"end_time":"2024-04-28T05:37:51.610812Z","start_time":"2024-04-28T05:37:51.600211Z"},"executionInfo":{"status":"aborted","timestamp":1716473902227,"user_tz":-180,"elapsed":18,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["state_encoding_features = ['SE-' + target_class for target_class in target_classes]\n","coordinate_encoding_features = ['DISTANCE_TO_CLUSTERS-'+target_class for target_class in target_classes]\n","geospacial_features = state_encoding_features + ['LATITUDE', 'LONGITUDE'] + coordinate_encoding_features"]},{"cell_type":"markdown","metadata":{"id":"Srwm4D3j2LOP"},"source":["# Time data"]},{"cell_type":"markdown","metadata":{"id":"X-Yvoy4yQMHS"},"source":["## EDA"]},{"cell_type":"markdown","metadata":{"id":"F9nHWM3JQrid"},"source":["We need to make some alternation on the data first in order to show pictures"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qse1Wz_LRjWs","ExecuteTime":{"end_time":"2024-04-28T05:37:52.633552Z","start_time":"2024-04-28T05:37:51.604665Z"},"executionInfo":{"status":"aborted","timestamp":1716473902228,"user_tz":-180,"elapsed":18,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["# save the original df, we will trasform df back later\n","original_df = df.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GknSg0x4QNvJ","ExecuteTime":{"end_time":"2024-04-28T05:37:57.323090Z","start_time":"2024-04-28T05:37:52.239122Z"},"executionInfo":{"status":"aborted","timestamp":1716473902231,"user_tz":-180,"elapsed":4993,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["# simple reformatting\n","df['DISCOVERY_DATE'] = pd.to_datetime(df['DISCOVERY_DATE'] - pd.Timestamp(0).to_julian_date(), unit='D')\n","df['DISCOVERY_TIME'] = pd.to_datetime(df['DISCOVERY_TIME'], format='%H%M', errors='coerce')\n","df['CONT_DATE']= pd.to_datetime(df['CONT_DATE'] - pd.Timestamp(0).to_julian_date(), unit='D')\n","df['CONT_TIME'] = pd.to_datetime(df['CONT_TIME'], format='%H%M', errors='coerce')\n","\n","# encode month and day of week (weekend or not.) Here we do not use numerical values becasue it might be non ordinal\n","df['MONTH'] = pd.DatetimeIndex(df['DISCOVERY_DATE']).strftime('%B')\n","df['DAY_OF_WEEK'] = pd.DatetimeIndex(df['DISCOVERY_DATE']).strftime('%A')\n","# notice that these two columns will be frequency encoded in the later section. So the later section depends on the execution of this section.\n","\n","# I want to pass fire year as a catagory, just like month and day of week, for onhot encoding\n","df['FIRE_YEAR'] = df['FIRE_YEAR'].astype('category')\n","\n","# Now I want to see if I can stuff in one more thing: Season. Basically a combination of months.\n","# And I will both one hot encode it and frequency encode it\n","df['SEASON'] = pd.DatetimeIndex(df['DISCOVERY_DATE']).month.map({1: 'Winter', 2: 'Winter', 3: 'Spring', 4: 'Spring',\n","                                                        5: 'Spring', 6: 'Summer', 7: 'Summer', 8: 'Summer',\n","                                                        9: 'Fall', 10: 'Fall', 11: 'Fall', 12: 'Winter'})\n","# For null time data: Discovery time, control date, control time etc.\n","# encode discovery time\n","df['DISCOVERY_HOUR'] = df['DISCOVERY_TIME'].dt.hour\n","\n","# encode delta time\n","df['DISCOVERY_DATETIME'] = pd.to_datetime(df['DISCOVERY_DATE'].astype(str) + ' ' + df['DISCOVERY_TIME'].dt.time.astype(str),\n","                                          format='%Y-%m-%d %H:%M:%S', errors='coerce')\n","\n","\n","df['CONT_DATETIME'] = pd.to_datetime(df['CONT_DATE'].astype(str) + ' ' + df['CONT_TIME'].dt.time.astype(str),\n","                                          format='%Y-%m-%d %H:%M:%S', errors='coerce')\n","\n","# Calculate the time difference\n","df['DELTA_TIME'] = (df['CONT_DATETIME'] - df['DISCOVERY_DATETIME']).dt.total_seconds()\n"]},{"cell_type":"markdown","metadata":{"id":"8FwBTfkyaSqF"},"source":["Let's see how a fire year affects the distribution of the target labels. We first calculate the distribution of the target classes when fixed a year then we use the distribution divided by the original distribution of the target classes."]},{"cell_type":"code","source":["plot_big_crosstab_vs_original(df, 'FIRE_YEAR', 2, 1)"],"metadata":{"id":"jtObKTTU1DDj","ExecuteTime":{"end_time":"2024-04-28T05:37:57.791279Z","start_time":"2024-04-28T05:37:57.327313Z"},"executionInfo":{"status":"aborted","timestamp":1716473902232,"user_tz":-180,"elapsed":4980,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can see that some target classes such as Arson and Railroad have higher percentage in the distribution in earlier years, and some other target classes, such as Powerline, have higher percentage in the distribution in recent years. This seems to be reasonable."],"metadata":{"id":"VYw-8MAiKJ37"}},{"cell_type":"markdown","metadata":{"id":"j9b_mxRHUiPQ"},"source":["Now we explore how the day of week and month would affect the number of fires.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tm-ez1c2Ul3w","ExecuteTime":{"end_time":"2024-04-28T05:37:58.224254Z","start_time":"2024-04-28T05:37:57.794957Z"},"executionInfo":{"status":"aborted","timestamp":1716473902233,"user_tz":-180,"elapsed":4968,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["# Plotting the graph\n","fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 10))\n","\n","\n","\n","df['day_of_week'] = pd.to_datetime(df['DISCOVERY_DATE']).dt.dayofweek\n","day_of_week_counts = df.groupby('day_of_week').size()\n","day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n","\n","axes[0].bar(range(7), day_of_week_counts, color='lightgreen')\n","axes[0].set_title('Number of Fires by Day of Week')\n","axes[0].set_xlabel('Day of Week')\n","axes[0].set_ylabel('Number of Fires')\n","axes[0].set_xticks(range(7))\n","axes[0].set_xticklabels(day_names, rotation=45)\n","axes[0].grid(axis='y', linestyle='--', alpha=0.7)\n","\n","df['month'] = pd.to_datetime(df['DISCOVERY_DATE']).dt.month\n","monthly_counts = df.groupby('month').size()\n","axes[1].bar(monthly_counts.index, monthly_counts, color='skyblue')\n","axes[1].set_title('Number of Fires by Month')\n","axes[1].set_xlabel('Month')\n","axes[1].set_ylabel('Number of Fires')\n","axes[1].grid(axis='y', linestyle='--', alpha=0.7)\n","\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","source":["We can see that on Saturdays and Sundays, the number of fires are slightly higher. And in March and April, and also in July and august."],"metadata":{"id":"dLyzre9pKQIo"}},{"cell_type":"markdown","metadata":{"id":"cQtB-F6tQOKx"},"source":["We plot out for each target class, how the number fluctuate in the year and in the week.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XGmzh8JzR1cO","ExecuteTime":{"end_time":"2024-04-28T05:37:58.553958Z","start_time":"2024-04-28T05:37:58.223029Z"},"executionInfo":{"status":"aborted","timestamp":1716473902233,"user_tz":-180,"elapsed":4954,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n","colors = ['blue', 'green', 'red', 'purple', 'orange', 'brown', 'pink', 'gray', 'cyan', 'magenta', 'yellow', 'black']\n","\n","grouped_monthly = df.groupby(['STAT_CAUSE_DESCR', 'month']).size().unstack(fill_value=0)\n","for i, fire_type in enumerate(grouped_monthly.index):\n","    axes[0].plot(grouped_monthly.columns, grouped_monthly.loc[fire_type], label=fire_type, color=colors[i])\n","\n","axes[0].set_title('Change of Number of Fires by Month')\n","axes[0].set_xlabel('Month')\n","axes[0].set_ylabel('Number of Fires')\n","axes[0].set_xticks(range(1, 13))\n","axes[0].legend(title='Fire Type')\n","axes[0].grid(axis='y', linestyle='--', alpha=0.7)\n","\n","grouped_daily = df.groupby(['STAT_CAUSE_DESCR', 'day_of_week']).size().unstack(fill_value=0)\n","for i, fire_type in enumerate(grouped_daily.index):\n","    axes[1].plot(grouped_daily.columns, grouped_daily.loc[fire_type], label=fire_type, color=colors[i])\n","\n","axes[1].set_title('Change of Number of Fires by Day of Week')\n","axes[1].set_xlabel('Day of Week')\n","axes[1].set_ylabel('Number of Fires')\n","axes[1].set_xticks(range(7))\n","axes[1].set_xticklabels(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], rotation=45)\n","axes[1].legend(title='Fire Type')\n","axes[1].grid(axis='y', linestyle='--', alpha=0.7)\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"X-MIbHJbkaJ5"},"source":["Then just like above, we will see how fixing a month and fixing a day of time would affect the distribution of the target classes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v-o-33PzkhM7","ExecuteTime":{"end_time":"2024-04-28T05:37:58.586083Z","start_time":"2024-04-28T05:37:58.554318Z"},"executionInfo":{"status":"aborted","timestamp":1716473902234,"user_tz":-180,"elapsed":4953,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["def plot_crosstab_heatmap_vs_original(df, feature_name, axes=None):\n","  cross_Vals = pd.crosstab(df[feature_name], df['STAT_CAUSE_DESCR'],  normalize='index')\n","  cross_Vals = cross_Vals.div(percentage_of_each_label, axis=1)\n","  if axes is None:\n","    sns.heatmap(cross_Vals, annot=True, annot_kws={\"fontsize\":4})\n","  else:\n","    sns.heatmap(cross_Vals, annot=True, annot_kws={\"fontsize\":4}, ax=axes)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cc05m5nOksTo","ExecuteTime":{"end_time":"2024-04-28T05:37:59.615614Z","start_time":"2024-04-28T05:37:58.560810Z"},"executionInfo":{"status":"aborted","timestamp":1716473902234,"user_tz":-180,"elapsed":4942,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n","plot_crosstab_heatmap_vs_original(df, 'month', axes[0])\n","plot_crosstab_heatmap_vs_original(df, 'day_of_week', axes[1])\n","plt.show()"]},{"cell_type":"markdown","source":["We can see that Fireworks are abnormally high in July, and Campfires are very high on Saturday and Sunday. Both make sense. So in order to further verify our hypothesis, let’s look at firework’s number during july."],"metadata":{"id":"mV9Hpi4eKeoe"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"B3WDjsGIsfaG","ExecuteTime":{"end_time":"2024-04-28T05:38:00.183144Z","start_time":"2024-04-28T05:37:59.613559Z"},"executionInfo":{"status":"aborted","timestamp":1716473902235,"user_tz":-180,"elapsed":4930,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["# Filter the data for the month of July\n","july_data = df[df['DISCOVERY_DATE'].dt.month == 7]\n","\n","# Filter the data for rows where the 'cause' column is 'firework'\n","firework_data = july_data[july_data['STAT_CAUSE_DESCR'] == 'Fireworks']\n","\n","# Group by date and count the occurrences of 'firework'\n","firework_counts = firework_data.groupby(firework_data['DISCOVERY_DATE'].dt.day).size()\n","# Plot the change in the number of 'firework' occurrences throughout July\n","plt.figure(figsize=(10, 6))\n","firework_counts.plot(kind='bar', color='blue')\n","plt.xlabel('Day of July')\n","plt.ylabel('Number of \"firework\" Occurrences')\n","plt.title('Change in Number of Fireworks Occurrences Throughout July')\n","plt.xticks(rotation=0)\n","plt.grid(axis='y', linestyle='--', alpha=0.7)\n","plt.show()"]},{"cell_type":"markdown","source":["We can see that the firework number increment is indeed because of July the 4th.\n"],"metadata":{"id":"HzevABZbKnoA"}},{"cell_type":"markdown","metadata":{"id":"YHfCSozqUaTP"},"source":["Also we want to look at how does each target class fluctuates during the year every day, so we plotted:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mav4N5RgSy16","ExecuteTime":{"end_time":"2024-04-28T05:38:04.292950Z","start_time":"2024-04-28T05:38:00.182809Z"},"executionInfo":{"status":"aborted","timestamp":1716473902235,"user_tz":-180,"elapsed":4920,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["# Create a figure and axes for the subplots\n","fig, axes = plt.subplots(4, 3, figsize=(12, 9))\n","\n","# Flatten the axes array for easier iteration\n","axes = axes.flatten()\n","\n","for i, target_class in enumerate(target_classes):\n","  target_class_df = df[df['STAT_CAUSE_DESCR'] == target_class]\n","  target_class_counts = target_class_df.groupby(df['DISCOVERY_DOY']).size()\n","  target_class_counts.plot(kind='bar', color='blue', ax=axes[i])\n","  axes[i].set_title(target_class)\n","  axes[i].set_xticks([])\n","  axes[i].set_xlabel('')\n","\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"EvZrOAepsYoz"},"source":["We can see that some target classes are more common in the summers and some are more common in the Spring, this explains why we see that the number of fires are higher in spring and summer. From here we also see that miscellaneous fireworks have overlaps Fireworks on July the fourth, and it also overlaps with many other classes. In order to make better predictions, maybe we should separate this class."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NUcuNmixmoCs","ExecuteTime":{"end_time":"2024-04-28T05:38:04.770045Z","start_time":"2024-04-28T05:38:04.291157Z"},"executionInfo":{"status":"aborted","timestamp":1716473902236,"user_tz":-180,"elapsed":4906,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["df =  df.dropna(subset=['DISCOVERY_TIME'])\n","plot_crosstab_heatmap_vs_original(df, 'DISCOVERY_HOUR')"]},{"cell_type":"markdown","source":["We can see that some columns like Campfire are more likely to happen during day time, and some other columns such as fireworks are more likely to happen during night time, and they all make sense."],"metadata":{"id":"CsaskBFuLwiz"}},{"cell_type":"markdown","source":["Something else we can do: we can see the correlation between two joint features: (feature_1 = a X feature_2 = b). For example, Summer in Alaska."],"metadata":{"id":"f_TGWjtJN8vU"}},{"cell_type":"markdown","metadata":{"id":"FOvr_jjEnUpe"},"source":["## Feature Engineering"]},{"cell_type":"markdown","source":["I will explain what I did in the folllowing function.  \n","We first convert time to the right format.  \n","Then from EDA we have seen that season, month and day of week really affects the final prediction. So we will add in this data.  \n","Then we know that july the fourth is very good indicator for predicting firework, so we will also add this feature.  \n","The second thing is we can see that Arson, debris buring, railroad and children have more instances in april. While Lighning and equipment use have more instances in July. So I tried to passed them into XGBoost, after a few experiment, we see that it performs better when we use frequency encoding to encode the columns.  \n","Then we add fire year.    \n","Then we calculate the time duration. Some of the CONT_DATE is null so we will have to handle it later. In the later chaper I will address this issue.  \n","Lastly we perform cyclic transformation on several columns, and it doesnot improve nor impair the performance.\n"],"metadata":{"id":"3jEbP3UGLC5l"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nwf8G4h_22Ev","ExecuteTime":{"end_time":"2024-04-28T05:38:04.842446Z","start_time":"2024-04-28T05:38:04.770272Z"},"executionInfo":{"status":"aborted","timestamp":1716473902236,"user_tz":-180,"elapsed":4904,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["import numpy as np\n","\n","def time_encoding(df):\n","  # simple reformatting\n","  df['DISCOVERY_DATE'] = pd.to_datetime(df['DISCOVERY_DATE'] - pd.Timestamp(0).to_julian_date(), unit='D')\n","  df['DISCOVERY_TIME'] = pd.to_datetime(df['DISCOVERY_TIME'], format='%H%M', errors='coerce')\n","  df['CONT_DATE']= pd.to_datetime(df['CONT_DATE'] - pd.Timestamp(0).to_julian_date(), unit='D')\n","  df['CONT_TIME'] = pd.to_datetime(df['CONT_TIME'], format='%H%M', errors='coerce')\n","  # encode independence day\n","  df['independence_day'] = (df['DISCOVERY_DATE'].dt.month == 7) & (df['DISCOVERY_DATE'].dt.day.isin([4, 5]))\n","\n","  # encode month and day of week (weekend or not.)\n","  df['MONTH'] = pd.DatetimeIndex(df['DISCOVERY_DATE']).strftime('%B')\n","  df['DAY_OF_WEEK'] = pd.DatetimeIndex(df['DISCOVERY_DATE']).strftime('%A')\n","  # notice that these two columns will be frequency encoded in the later section. So the later section depends on the execution of this section.\n","\n","  # I want to pass fire year as a catagory, just like month and day of week, for onhot encoding\n","  df['FIRE_YEAR'] = df['FIRE_YEAR'].astype('category')\n","\n","  # Now I want to see if I can stuff in one more thing: Season. Basically a combination of months.\n","  # And I will both one hot encode it and frequency encode it\n","  df['SEASON'] = pd.DatetimeIndex(df['DISCOVERY_DATE']).month.map({1: 'Winter', 2: 'Winter', 3: 'Spring', 4: 'Spring',\n","                                                          5: 'Spring', 6: 'Summer', 7: 'Summer', 8: 'Summer',\n","                                                          9: 'Fall', 10: 'Fall', 11: 'Fall', 12: 'Winter'})\n","  # For null time data: Discovery time, control date, control time etc.\n","  # encode discovery time\n","  df['DISCOVERY_HOUR'] = df['DISCOVERY_TIME'].dt.hour\n","\n","  # encode delta time\n","  df['DISCOVERY_DATETIME'] = pd.to_datetime(df['DISCOVERY_DATE'].astype(str) + ' ' + df['DISCOVERY_TIME'].dt.time.astype(str),\n","                                            format='%Y-%m-%d %H:%M:%S', errors='coerce')\n","\n","\n","  df['CONT_DATETIME'] = pd.to_datetime(df['CONT_DATE'].astype(str) + ' ' + df['CONT_TIME'].dt.time.astype(str),\n","                                            format='%Y-%m-%d %H:%M:%S', errors='coerce')\n","\n","  # Calculate the time difference\n","  df['DELTA_TIME'] = (df['CONT_DATETIME'] - df['DISCOVERY_DATETIME']).dt.total_seconds()\n","\n","  # Cyclic transformation for DOY, Month, Week, Hour\n","  df['SIN_DISCOVERY_DOY'] = np.sin(2*np.pi*df['DISCOVERY_DOY']/366)\n","  df['COS_DISCOVERY_DOY'] = np.cos(2*np.pi*df['DISCOVERY_DOY']/366)\n","\n","  df['SIN_MONTH'] = np.sin(2*np.pi*pd.DatetimeIndex(df['DISCOVERY_DATE']).month/12)\n","  df['COS_MONTH'] = np.cos(2*np.pi*pd.DatetimeIndex(df['DISCOVERY_DATE']).month/12)\n","\n","  df['SIN_DAY_OF_WEEK'] = np.sin(2*np.pi*pd.DatetimeIndex(df['DISCOVERY_DATE']).dayofweek/7)\n","  df['COS_DAY_OF_WEEK'] = np.cos(2*np.pi*pd.DatetimeIndex(df['DISCOVERY_DATE']).dayofweek/7)\n","\n","  df['SIN_HOUR'] = np.sin(2*np.pi*df['DISCOVERY_HOUR']/24)\n","  df['COS_HOUR'] = np.cos(2*np.pi*df['DISCOVERY_HOUR']/24)\n","\n","  return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X4G8hn_5Q6Gj","ExecuteTime":{"end_time":"2024-04-28T05:38:04.901270Z","start_time":"2024-04-28T05:38:04.777158Z"},"executionInfo":{"status":"aborted","timestamp":1716473903311,"user_tz":-180,"elapsed":85,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["encoded_time_data = ['independence_day', 'MONTH', 'DAY_OF_WEEK', 'FIRE_YEAR', 'DISCOVERY_HOUR', 'DELTA_TIME',\n","                     'SIN_DISCOVERY_DOY', 'COS_DISCOVERY_DOY', 'SIN_MONTH', 'COS_MONTH',\n","                     'SIN_DAY_OF_WEEK', 'COS_DAY_OF_WEEK', 'SIN_HOUR', 'COS_HOUR']"]},{"cell_type":"markdown","metadata":{"id":"i7fDBOpSja74"},"source":["  Result of some experiments: I tried to put the original data along with the frequency encoded data together into the XGBoost, but it lowers the performance.\n"]},{"cell_type":"markdown","metadata":{"id":"CDN8t5CPt9IV"},"source":["In order to decide how to handle the null value in DELTA_TIME, let's show the relationship between delta time and FIRE_SIZE and FIRE_SIZE_CLASS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IB2I7C3KuDZC","ExecuteTime":{"end_time":"2024-04-28T05:38:05.096158Z","start_time":"2024-04-28T05:38:04.822063Z"},"executionInfo":{"status":"aborted","timestamp":1716473903311,"user_tz":-180,"elapsed":85,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["feature1 = 'FIRE_SIZE'\n","feature2 = 'DELTA_TIME'\n","\n","plt.figure(figsize=(8, 6))\n","plt.scatter(df[feature1], df[feature2], alpha=0.5)\n","plt.title(f'Scatter Plot of {feature1} vs {feature2}')\n","plt.xlabel(feature1)\n","plt.ylabel(feature2)\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XbHxapXyuKO0","ExecuteTime":{"end_time":"2024-04-28T05:38:05.258369Z","start_time":"2024-04-28T05:38:05.085294Z"},"executionInfo":{"status":"aborted","timestamp":1716473903312,"user_tz":-180,"elapsed":85,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["feature3 = 'FIRE_SIZE_CLASS'\n","\n","grouped_data = df.groupby(feature3)[feature2].agg(['mean']).reset_index()\n","\n","# Plot bar chart for each category\n","plt.bar(grouped_data[feature3], grouped_data['mean'])\n","\n","plt.title(f'Mean and Variance of {feature3} by {feature3}')\n","plt.xlabel(feature3)\n","plt.ylabel('Value')\n","plt.show()"]},{"cell_type":"markdown","source":["We can see that delta time seems to have correlation with FIRE_SIZE_CLASS, we will adress this in the later chapters."],"metadata":{"id":"LZtIi_kbOmWV"}},{"cell_type":"markdown","metadata":{"id":"506xLvgfrExn"},"source":["Remeber to return df to original"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yFzXKcHnvgJA","ExecuteTime":{"end_time":"2024-04-28T05:38:05.735906Z","start_time":"2024-04-28T05:38:05.196457Z"},"executionInfo":{"status":"aborted","timestamp":1716473903312,"user_tz":-180,"elapsed":84,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["df = original_df.copy()"]},{"cell_type":"markdown","metadata":{"id":"bguPhrK7f56L"},"source":["# Catagorical Features"]},{"cell_type":"markdown","metadata":{"id":"HokDN_0Y-0EM"},"source":["## EDA"]},{"cell_type":"markdown","metadata":{"id":"xCuNq9Kn-2XU"},"source":["First we analyze how each categorical class affects  the target classes, in order to determine if they are worth encoding. For example, the analisis we do for NWCG_REPORTING_AGENCY , OWNER_DESCR, SOURCE_SYSTEM_TYPE, FIRE_SIZE_CLASS\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JPYzA-sg--zZ","ExecuteTime":{"end_time":"2024-04-28T05:38:06.834276Z","start_time":"2024-04-28T05:38:05.730983Z"},"executionInfo":{"status":"aborted","timestamp":1716473903313,"user_tz":-180,"elapsed":84,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 6))\n","\n","plot_crosstab_heatmap_vs_original(df, 'NWCG_REPORTING_AGENCY', axes[0,0])\n","plot_crosstab_heatmap_vs_original(df, 'OWNER_DESCR', axes[0,1])\n","plot_crosstab_heatmap_vs_original(df, 'SOURCE_SYSTEM_TYPE', axes[1,0])\n","plot_crosstab_heatmap_vs_original(df, 'FIRE_SIZE_CLASS', axes[1, 1])\n","plt.show()"]},{"cell_type":"markdown","source":["We divided the categorical feature into two groups: HC_features, which encompasses numerous possible value options (High Cardinality), and LC_features, which comprises fewer value options."],"metadata":{"id":"F42GOnarO5hg"}},{"cell_type":"markdown","metadata":{"id":"0Az1s1bz_8CH"},"source":["## Feature Engineering"]},{"cell_type":"markdown","metadata":{"id":"-ckeMW-4AGLV"},"source":["### Frequency Encoding"]},{"cell_type":"markdown","metadata":{"id":"Q7bBEVNwAJP9"},"source":["We will train an encoder based on the training set, and then use it to encode both training set and evaluation set.  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KWXQ9LIE457Q","ExecuteTime":{"end_time":"2024-04-28T05:38:06.841711Z","start_time":"2024-04-28T05:38:06.833095Z"},"executionInfo":{"status":"aborted","timestamp":1716473903313,"user_tz":-180,"elapsed":84,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["# These are High cardinality catagorical features\n","HC_features = ['NWCG_REPORTING_UNIT_ID', 'NWCG_REPORTING_UNIT_NAME',\n","               'SOURCE_REPORTING_UNIT', 'SOURCE_REPORTING_UNIT_NAME']\n","LC_features = ['FIRE_SIZE_CLASS',\n","                'NWCG_REPORTING_AGENCY',\n","                'OWNER_CODE', 'OWNER_DESCR',\n","                'SOURCE_SYSTEM', 'SOURCE_SYSTEM_TYPE',]\n","catagorical_time_data = ['MONTH', 'DAY_OF_WEEK', 'FIRE_YEAR', 'SEASON', 'DISCOVERY_HOUR']\n","catagorical_geospacial_data = ['STATE', 'COUNTY', 'FIPS_CODE', 'FIPS_NAME']\n","catagorical_features = HC_features + LC_features + catagorical_time_data + catagorical_geospacial_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dI35yNaf6IX_","ExecuteTime":{"end_time":"2024-04-28T05:38:06.875695Z","start_time":"2024-04-28T05:38:06.844485Z"},"executionInfo":{"status":"aborted","timestamp":1716473903314,"user_tz":-180,"elapsed":84,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["#  generic function for frequency encoding\n","frequency_encoder_map = {}\n","def train_frequency_encoders(df):\n","  for feature in catagorical_features:\n","    frequency_encoder = df[feature].value_counts(normalize=True)\n","    frequency_encoder_map[feature] = frequency_encoder\n","\n","def frequency_encoding(df):\n","  for feature in catagorical_features:\n","    df['FE-'+ feature] = df[feature].map(frequency_encoder_map[feature])\n","    # Convert to numeric, coerce errors to NaN, else we cannot fillna(0)\n","    df['FE-'+ feature] = pd.to_numeric(df['FE-'+ feature], errors='coerce')\n","    df['FE-'+ feature] = df['FE-'+ feature].fillna(0)\n","  return df"]},{"cell_type":"markdown","source":["Result of Experiment: we try to use one hot encoding for low cardinality features and frequency encoding for high cardinality features. However, it turns out that using frequency encoding for every thing performs better. Except for null columns and states. In addition, if we pass both the original feature and the frequency encoded feature to XGBoost, it makes the performance worse."],"metadata":{"id":"Cwhf6LTXPLzP"}},{"cell_type":"markdown","metadata":{"id":"tyzWb6FlvUWF"},"source":["# Numerical"]},{"cell_type":"markdown","metadata":{"id":"9l-3UUnHLC9k"},"source":["## EDA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SyCWcfjZLEsg","ExecuteTime":{"end_time":"2024-04-28T05:38:07.169774Z","start_time":"2024-04-28T05:38:06.847450Z"},"executionInfo":{"status":"aborted","timestamp":1716473903314,"user_tz":-180,"elapsed":84,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["df.describe()"]},{"cell_type":"markdown","metadata":{"id":"RCtQu7fvPlKW"},"source":["Let's look at how fire size is distributed among class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tslPMGtqOmxK","ExecuteTime":{"end_time":"2024-04-28T05:38:07.611689Z","start_time":"2024-04-28T05:38:07.167029Z"},"executionInfo":{"status":"aborted","timestamp":1716473903314,"user_tz":-180,"elapsed":83,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","# Group by 'feature_1' and calculate sum, average, and median of 'feature_2' within each group\n","grouped_df = df.groupby('STAT_CAUSE_DESCR')['FIRE_SIZE'].agg(['sum', 'mean', 'median'])\n","\n","# Create a figure and subplots\n","fig, axes = plt.subplots(3, 1, figsize=(10, 15))\n","\n","# Plot sum of 'feature_2'\n","grouped_df['sum'].plot(kind='bar', ax=axes[0])\n","axes[0].set_title('Sum of FIRE_SIZE for each class in STAT_CAUSE_DESCR')\n","axes[0].set_ylabel('Sum')\n","\n","# Plot average of 'feature_2'\n","grouped_df['mean'].plot(kind='bar', ax=axes[1])\n","axes[1].set_title('Average of FIRE_SIZE for each class in STAT_CAUSE_DESCR')\n","axes[1].set_ylabel('Average')\n","\n","# Plot median of 'feature_2'\n","grouped_df['median'].plot(kind='bar', ax=axes[2])\n","axes[2].set_title('Median of FIRE_SIZE for each class in STAT_CAUSE_DESCR')\n","axes[2].set_ylabel('Median')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"EsVEEGdGSuqa"},"source":["we can see that there is a correlation between the fire size and the target classes. So we can understand that this feature is important for our model."]},{"cell_type":"markdown","source":["## Feature Engineering"],"metadata":{"id":"MiQyyY9nQCcD"}},{"cell_type":"markdown","source":["For FIRE_SIZE, we tried to take the log value of it, however it does not improve or impair the performance, so it's redundent to do so. Another thing is we see that FIRE_SIZE have many outlier points, we will address this issue in the later chapter."],"metadata":{"id":"Dk_tCcOvQG6O"}},{"cell_type":"markdown","metadata":{"id":"-vFEIow1_GII"},"source":["# Additional information"]},{"cell_type":"markdown","source":["At this experiment we thought  about new features that could correlate to some of the labels in the target and add heuristics for them.\n","The Experiment involved downloading the NOAA Storm Events Database dataset and preparing it for analysis. The preparation included converting date columns to datetime objects and filtering the dataset to include only records from the years 1992 to 2015, aligning with the timeframe of the wildfire dataset.\n","To facilitate matching states between the two datasets, a dictionary of state abbreviations was created. This dictionary was then used to replace full state names with their corresponding abbreviations in the storm events dataset.\n","Subsequently, the focus shifted to the wildfire dataset. I introduced a new column, 'STORM', which served as a boolean indicator to signify whether a wildfire occurred concurrently with a storm in the same state. This determination was made by checking if the combination of the wildfire's discovery date and state matched any entries in the storm events dataset.\n"],"metadata":{"id":"Mp0kks8JQgXw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"PTFvH4l_U-D3","ExecuteTime":{"end_time":"2024-04-28T05:38:07.987237Z","start_time":"2024-04-28T05:38:07.612140Z"},"executionInfo":{"status":"aborted","timestamp":1716473903315,"user_tz":-180,"elapsed":84,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["df_stormevents = pd.read_csv('/content/drive/MyDrive/Projects/FirePrediction/storm_events.csv',index_col=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tikEM7Lo_K06","ExecuteTime":{"end_time":"2024-04-28T05:38:10.093731Z","start_time":"2024-04-28T05:38:07.993718Z"},"executionInfo":{"status":"aborted","timestamp":1716473903315,"user_tz":-180,"elapsed":83,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["# train storm encoder, we will just look at first day of storm\n","df_stormevents['BEGIN_DATE'] = pd.to_datetime(df_stormevents['BEGIN_DATE'])\n","storm_by_state = df_stormevents.groupby(['BEGIN_DATE', 'STATE']).groups.keys()\n","\n","def encode_storm_data(df):\n","  df['STORM'] = False\n","  df['STORM'] = df.apply(lambda row: (row['DISCOVERY_DATE'],\n","                                    row['STATE']) in storm_by_state if row['STATE'] else None, axis=1)\n","  return df"]},{"cell_type":"markdown","metadata":{"id":"CzVBloSpLaZ0"},"source":["# Leakage"]},{"cell_type":"markdown","metadata":{"id":"E6NT8yRAEvik"},"source":["Leakage are information that we are not suppose to know during prediction. From data set description, we can determin that there are some columns is either leakage or useless. They should contribute to prediction. So we will not use these columns.  \n"]},{"cell_type":"markdown","metadata":{"id":"6OyJoktQGiLw"},"source":["Firstly, OBJECTID, FOD_ID and FPA_ID are irrelavent features, because they are id used to track samples in database. We can see that they are somehow correlated to other features, but we are not suppose to know the id before the sample is stored in the database. So we will consider this a leakage."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q9UrRPldEmog","ExecuteTime":{"end_time":"2024-04-28T05:38:10.529983Z","start_time":"2024-04-28T05:38:10.091142Z"},"executionInfo":{"status":"aborted","timestamp":1716473903316,"user_tz":-180,"elapsed":84,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["numerical_columns = ['OBJECTID','FOD_ID', 'FIRE_YEAR','DISCOVERY_DATE',\n","               'DISCOVERY_DOY',\t'DISCOVERY_TIME',\t'CONT_DATE',\t'CONT_DOY',\n","               'CONT_TIME',\t'FIRE_SIZE',\t'LATITUDE',\t'LONGITUDE','OWNER_CODE','FIPS_CODE']\n","df_for_correlation = df[numerical_columns]\n","sns.heatmap(df_for_correlation.corr().abs())"]},{"cell_type":"markdown","source":["Result of Experiment: there are three ID columns: 'OBJECTID', 'FOD_ID', and 'FPA_ID', which we have observed do not contribute to improving the model. We are concerned that even if they were to help, they could potentially lead to data leakage.\n"],"metadata":{"id":"ttLFy4HQQ3GZ"}},{"cell_type":"markdown","metadata":{"id":"OtA9A50hGzp9"},"source":["Then we will not use FIRE_NAME and FIRE_CODE since from the description of this two columns, we are not suppose to know the fire name or fire code at the time of prediction."]},{"cell_type":"markdown","metadata":{"id":"Zsd-lhxSLYGb"},"source":["# Anomaly detection"]},{"cell_type":"markdown","metadata":{"id":"vsl-filMprtL"},"source":["We will just do a short anomoly detection here. We will look at fire size"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PbkYKPB4pz3B","ExecuteTime":{"end_time":"2024-04-28T05:38:10.531323Z","start_time":"2024-04-28T05:38:10.526038Z"},"executionInfo":{"status":"aborted","timestamp":1716473903316,"user_tz":-180,"elapsed":83,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def plot_mean_variance_by_category(feature1, feature3, df, rotate_x_lable=False):\n","    # Group data by categories of feature3 and calculate mean and variance for each group\n","    grouped_data = df.groupby(feature3)[feature1].agg(['mean', 'std']).reset_index()\n","\n","    # Plot bar chart for each category\n","    plt.bar(grouped_data[feature3], grouped_data['mean'], yerr= grouped_data['std'])\n","\n","    plt.title(f'Mean and Variance of {feature1} by {feature3}')\n","    if rotate_x_lable == True:\n","      plt.xticks(rotation=45, ha='right')\n","    plt.xlabel(feature3)\n","    plt.ylabel('Value')\n","    plt.show()\n","\n","def plot_box_plot(feature1, feature3, df, rotate_x_lable=False):\n","    df.boxplot(column=feature1, by=feature3)\n","\n","    plt.title(f'Mean and Variance of {feature1} by {feature3}')\n","    if rotate_x_lable == True:\n","      plt.xticks(rotation=45, ha='right')\n","    plt.xlabel(feature3)\n","    plt.ylabel('Value')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MH2bwzPdp_-o","ExecuteTime":{"end_time":"2024-04-28T05:38:10.695498Z","start_time":"2024-04-28T05:38:10.542691Z"},"executionInfo":{"status":"aborted","timestamp":1716473903316,"user_tz":-180,"elapsed":83,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["plot_mean_variance_by_category('FIRE_SIZE', 'FIRE_SIZE_CLASS', df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"woInUaT8qOK2","ExecuteTime":{"end_time":"2024-04-28T05:38:11.273334Z","start_time":"2024-04-28T05:38:10.685286Z"},"executionInfo":{"status":"aborted","timestamp":1716473903317,"user_tz":-180,"elapsed":83,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["plot_box_plot('FIRE_SIZE', 'FIRE_SIZE_CLASS', df)"]},{"cell_type":"markdown","metadata":{"id":"W-XtNF7OqDDc"},"source":["We can see that the variance is huge, and there are a lot of fliers. Let's try to get rid of these fliers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M8cwvuzlqmP9","ExecuteTime":{"end_time":"2024-04-28T05:38:11.273594Z","start_time":"2024-04-28T05:38:11.229192Z"},"executionInfo":{"status":"aborted","timestamp":1716473903317,"user_tz":-180,"elapsed":83,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["def drop_outliers(df):\n","  non_outlier_list = []\n","  for fire_size_class in df['FIRE_SIZE_CLASS'].unique():\n","    df_by_fire_size = df[df['FIRE_SIZE_CLASS']==fire_size_class]\n","    # Step 1: Calculate Q1 and Q3\n","    Q1 = df_by_fire_size['FIRE_SIZE'].quantile(0.25)\n","    Q3 = df_by_fire_size['FIRE_SIZE'].quantile(0.75)\n","\n","    # Step 2: Calculate IQR\n","    IQR = Q3 - Q1\n","\n","    # Step 3: Define threshold for outliers\n","    threshold = 1.5\n","\n","    # Step 4: Identify outliers\n","    non_outlier = df_by_fire_size[(df_by_fire_size['FIRE_SIZE'] >= Q1 - threshold * IQR) & (df_by_fire_size['FIRE_SIZE'] <= Q3 + threshold * IQR)]\n","    non_outlier_list.append(non_outlier)\n","  df_non_outlier = pd.concat(non_outlier_list)\n","  return df_non_outlier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZdMacE3xq-KZ","ExecuteTime":{"end_time":"2024-04-28T05:38:12.362360Z","start_time":"2024-04-28T05:38:11.259330Z"},"executionInfo":{"status":"aborted","timestamp":1716473903318,"user_tz":-180,"elapsed":83,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["df_non_outlier = drop_outliers(df)"]},{"cell_type":"markdown","metadata":{"id":"iOrV4PbHrTev"},"source":["And let's see the fire size afterwards"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3IqYsBA-rWIU","ExecuteTime":{"end_time":"2024-04-28T05:38:12.505392Z","start_time":"2024-04-28T05:38:12.369155Z"},"executionInfo":{"status":"aborted","timestamp":1716473903318,"user_tz":-180,"elapsed":83,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["plot_mean_variance_by_category('FIRE_SIZE', 'FIRE_SIZE_CLASS', df_non_outlier)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FY1foa1srYzG","ExecuteTime":{"end_time":"2024-04-28T05:38:12.845343Z","start_time":"2024-04-28T05:38:12.508891Z"},"executionInfo":{"status":"aborted","timestamp":1716473903318,"user_tz":-180,"elapsed":82,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["plot_box_plot('FIRE_SIZE', 'FIRE_SIZE_CLASS', df_non_outlier)"]},{"cell_type":"markdown","metadata":{"id":"os013rSlr1We"},"source":["Result of Experiment: getting rid of the outliers doesn't really helped, but rather it decreased the accuracy by a little. For more detail see Evaluation XGBoost section."]},{"cell_type":"markdown","metadata":{"id":"YcOCqLhXpoZQ"},"source":["# Balancing Data"]},{"cell_type":"markdown","metadata":{"id":"K2-jzOpcF91O"},"source":["## EDA"]},{"cell_type":"markdown","metadata":{"id":"p6Zq21qbGAIW"},"source":["We can see that the data is imbalanced"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r9EdpEunGCjB","ExecuteTime":{"end_time":"2024-04-28T05:38:12.984263Z","start_time":"2024-04-28T05:38:12.877317Z"},"executionInfo":{"status":"aborted","timestamp":1716473903319,"user_tz":-180,"elapsed":82,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["df['STAT_CAUSE_DESCR'].value_counts().plot(kind='bar')\n","\n","# Add labels and title\n","plt.title('Number of Occurrences of Each Unique Value in STAT_CAUSE_DESCR')\n","plt.xlabel('Cause Description')\n","plt.ylabel('Count')\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"code","source":["df['STAT_CAUSE_DESCR'].value_counts()"],"metadata":{"id":"oFt9nBgZmF9N","ExecuteTime":{"end_time":"2024-04-28T05:38:13.055220Z","start_time":"2024-04-28T05:38:13.003964Z"},"executionInfo":{"status":"aborted","timestamp":1716473903319,"user_tz":-180,"elapsed":68,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HuH9kw05sIW7"},"source":["We will try to balance the data by passing in the sample weight given by inverse of the target class's porportion."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Qr8v1cJseGV","ExecuteTime":{"end_time":"2024-04-28T05:38:13.055408Z","start_time":"2024-04-28T05:38:13.008608Z"},"executionInfo":{"status":"aborted","timestamp":1716473903319,"user_tz":-180,"elapsed":67,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["import numpy as np\n","def calculate_sample_weights(y_train):\n","  class_counts = np.bincount(y_train)\n","  total_example = np.sum(class_counts)\n","  class_weights = total_example/(len(class_counts)* class_counts)\n","  sample_weights = class_weights[y_train]\n","  return sample_weights"]},{"cell_type":"markdown","source":["Result of Experiment: Balancing doesnot work, because we performed poorly in class \"Smoking\", but this class is a big class, balancing only assign this class less wight than 1."],"metadata":{"id":"72HK5Sq5mNt1"}},{"cell_type":"markdown","metadata":{"id":"JnIESSmR3_BE"},"source":["# Null columns"]},{"cell_type":"markdown","metadata":{"id":"xskG0o0EEDlD"},"source":["## EDA"]},{"cell_type":"markdown","source":["Let's look at the null columns"],"metadata":{"id":"6BoTwN6-TAWF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5RzhaEfnfyxO","ExecuteTime":{"end_time":"2024-04-28T05:38:14.688198Z","start_time":"2024-04-28T05:38:13.011581Z"},"executionInfo":{"status":"aborted","timestamp":1716473903320,"user_tz":-180,"elapsed":68,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["column_stats = []\n","for column_name in df.columns:\n","    column = df[column_name]\n","    num_null = column.isnull().sum()\n","    total_values = len(column)\n","    null_percent = (num_null / total_values) * 100\n","    num_of_unique_values = len(column.unique())\n","    column_stats.append((column_name, num_null, null_percent,num_of_unique_values))\n","\n","column_stats_df = pd.DataFrame(column_stats, columns=['ColumnName', 'NullNumber', 'NullPercentage', \"UniqueValueNumber\"])\n","column_stats_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y5IyoaKiWxNA","ExecuteTime":{"end_time":"2024-04-28T05:38:14.698733Z","start_time":"2024-04-28T05:38:14.686599Z"},"executionInfo":{"status":"aborted","timestamp":1716473903320,"user_tz":-180,"elapsed":67,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["# we will not encode all of them, just encode these:\n","null_features = ['LOCAL_FIRE_REPORT_ID', 'LOCAL_INCIDENT_ID',\n","                         'ICS_209_INCIDENT_NUMBER', 'ICS_209_NAME', 'MTBS_ID', 'MTBS_FIRE_NAME', 'COMPLEX_NAME',\n","                         'DISCOVERY_TIME', 'CONT_DATE', 'CONT_DOY', 'CONT_TIME',\n","                         'COUNTY', 'FIPS_CODE', 'FIPS_NAME']\n"]},{"cell_type":"markdown","metadata":{"id":"99qRnLeyDajA"},"source":["Let's see how null columns can affect the distribution of models. The math behind it is just as explained above."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y9KfrqY3Djs6","ExecuteTime":{"end_time":"2024-04-28T05:38:25.969528Z","start_time":"2024-04-28T05:38:14.701630Z"},"executionInfo":{"status":"aborted","timestamp":1716473903321,"user_tz":-180,"elapsed":67,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["label_distribution_pd_series = []\n","target_column = 'STAT_CAUSE_DESCR'\n","for feature_column in null_features:\n","  # Filter rows where the specified feature is null\n","  missing_feature_df = df[df[feature_column].isnull()]\n","  # Get the distribution of target labels for rows where the feature is null\n","  label_distribution = missing_feature_df[target_column].value_counts(normalize=True)\n","  label_distribution.name = feature_column\n","  label_distribution_pd_series.append(label_distribution)\n","value_count_label_distribution_df = pd.concat(label_distribution_pd_series, axis=1)\n","\n","label_distribution_pd_series = []\n","target_column = 'STAT_CAUSE_DESCR'\n","for feature_column in null_features:\n","  # Filter rows where the specified feature is null\n","  missing_feature_df = df[~df[feature_column].isnull()]\n","  # Get the distribution of target labels for rows where the feature is null\n","  label_distribution = missing_feature_df[target_column].value_counts(normalize=True)\n","  label_distribution.name = feature_column\n","  label_distribution_pd_series.append(label_distribution)\n","value_count_not_null_label_distribution_df = pd.concat(label_distribution_pd_series, axis=1)\n","\n","percentage_of_each_label = df[target_column].value_counts(normalize=True)\n","percentage_of_each_label\n","\n","diff_value_count_label_distribution_df = value_count_label_distribution_df.div(percentage_of_each_label, axis=0)\n","diff_value_count_not_null_label_distribution_df = value_count_not_null_label_distribution_df.div(percentage_of_each_label, axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ou8DioiMD_RT","ExecuteTime":{"end_time":"2024-04-28T05:38:27.619942Z","start_time":"2024-04-28T05:38:25.904627Z"},"executionInfo":{"status":"aborted","timestamp":1716473903321,"user_tz":-180,"elapsed":67,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 3))\n","\n","# plot two plots\n","sns.heatmap(diff_value_count_label_distribution_df, annot=True, cmap='viridis', fmt='.2f', annot_kws={\"fontsize\":6}, ax=ax[0])\n","sns.heatmap(diff_value_count_not_null_label_distribution_df, annot=True, cmap='viridis', fmt='.2f', annot_kws={\"fontsize\":6}, ax=ax[1])\n","\n","plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)\n"]},{"cell_type":"markdown","source":["The left picture is when these columns are null, how much does it affect the distribution of the target classes. The right picture is when the column is not null, how would it affect the distribution.  \n","We can see that although many features, such as COMPLEX_NAME, have 99% null rate. When it is not null, it provides a great insight on predicting lightning."],"metadata":{"id":"4kK9akWATVr0"}},{"cell_type":"markdown","metadata":{"id":"QAg3yYyZIcWl"},"source":["Let's see how null features are correlated"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nASJS_hDIh8Y","ExecuteTime":{"end_time":"2024-04-28T05:38:29.962717Z","start_time":"2024-04-28T05:38:27.587152Z"},"executionInfo":{"status":"aborted","timestamp":1716473903321,"user_tz":-180,"elapsed":66,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["import missingno as msno\n","msno.heatmap(df)"]},{"cell_type":"markdown","source":["As we guessed, DISCOVERY_DATE CONT_DATE CONT_DOY CONT_TIME are correlated, COUNTY FIPS_CODE FIPS name are correlated."],"metadata":{"id":"vYt7qQypT0hC"}},{"cell_type":"markdown","metadata":{"id":"7_cbqT2JEJy9"},"source":["## Feature Engineering"]},{"cell_type":"markdown","metadata":{"id":"P_xBY66cKtym"},"source":["### Encoding"]},{"cell_type":"markdown","metadata":{"id":"TAaSQgKcUXcV"},"source":["There are five columns that are 99% null, from EDA section, we see that if they are not null, it will help with the prediction of some columns.  \n","For other features, it seems like encode them as null or not null both have benefits."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s9lv7sUJYqqc","ExecuteTime":{"end_time":"2024-04-28T05:38:29.991991Z","start_time":"2024-04-28T05:38:29.961857Z"},"executionInfo":{"status":"aborted","timestamp":1716473903322,"user_tz":-180,"elapsed":66,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["# fucntion that will encode this four columns\n","def null_encoding(df):\n","  # these columns will be encoded as 1 - null, 0 - not null\n","  for feature in null_features:\n","    df['NE-'+feature] = df[feature].isnull().astype(int)\n","  return df\n"]},{"cell_type":"markdown","metadata":{"id":"6XAoRXucUTuX"},"source":["Results of Experiments: If we pass in null features as is to XGBoost, it will fill in the null values. Although the training performance becomes really low, the validation error are very high."]},{"cell_type":"markdown","metadata":{"id":"X_8Kb6XyIgMe"},"source":["### Imputation"]},{"cell_type":"markdown","metadata":{"id":"_hjUhrDLI5Wa"},"source":["There are a few columns that contains null in our training data. We will see if imputation help with accuracy."]},{"cell_type":"markdown","source":["We will fill null of county by the state they are in."],"metadata":{"id":"-TsrB1mcUgMC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tPJ8vCykJIe7","ExecuteTime":{"end_time":"2024-04-28T05:38:29.993156Z","start_time":"2024-04-28T05:38:29.962337Z"},"executionInfo":{"status":"aborted","timestamp":1716473903322,"user_tz":-180,"elapsed":66,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["def imputate_COUNTY(df):\n","  df[\"COUNTY\"] = df[\"COUNTY\"].str.lower()\n","  df.loc[df['COUNTY'].isnull(), 'COUNTY'] = df.loc[df['COUNTY'].isnull(),'STATE']\n","  return df"]},{"cell_type":"markdown","source":["Result of Experiment: it doesnot help or impair the performance. So we will keep it, since not every model can fill in null values like XGBoost, it will help with model selection."],"metadata":{"id":"pSdkLtoiNsl-"}},{"cell_type":"markdown","source":["As explained in the Time data section, we can see a correlation between DEALTA_TIME and FIRE_SIZE_CLASS. So we will impute DELTA_TIME by the mean of firesize class they are in."],"metadata":{"id":"nerFqdNlUvwJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"JWOP0aIgJc1W","ExecuteTime":{"end_time":"2024-04-28T05:38:29.993853Z","start_time":"2024-04-28T05:38:29.962442Z"},"executionInfo":{"status":"aborted","timestamp":1716473903323,"user_tz":-180,"elapsed":66,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["DELTA_TIME_means_by_class_map = {}\n","def train_DELTA_TIME_IMPUTATOR(df):\n","  global DELTA_TIME_means_by_class_map\n","  DELTA_TIME_means_by_class_map = df.groupby('FIRE_SIZE_CLASS')['DELTA_TIME'].agg(['mean'])['mean'].to_dict()\n","\n","def fill_missing(row):\n","    if pd.isna(row['DELTA_TIME']):\n","        return DELTA_TIME_means_by_class_map[row['FIRE_SIZE_CLASS']]\n","    else:\n","        return row['DELTA_TIME']\n","def imputate_DELTA_TIME(df):\n","  df['DELTA_TIME'] = df.apply(fill_missing, axis=1)\n","  return df"]},{"cell_type":"markdown","source":["Result of Experiment: It doesnot help with the over performance, however, when passed in null values without imputation, the training error is lowered while the validation error stays the same."],"metadata":{"id":"e0tm1x8ZOJla"}},{"cell_type":"markdown","metadata":{"id":"32KlkDIcKwYM"},"source":["### Drop Null rows"]},{"cell_type":"markdown","source":["Instead of dropping features that contains null, we tried to drop null rows, and see how that would afect the performance."],"metadata":{"id":"spC4EdS1VI15"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5mO67UkZJn-e","ExecuteTime":{"end_time":"2024-04-28T05:38:29.995599Z","start_time":"2024-04-28T05:38:29.962539Z"},"executionInfo":{"status":"aborted","timestamp":1716473903323,"user_tz":-180,"elapsed":66,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["def drop_null_time_rows(X, y):\n","  df = X\n","  df['STAT_CAUSE_DESCR'] = y\n","  df = df.dropna(subset=['DISCOVERY_TIME']).copy()\n","  y = df['STAT_CAUSE_DESCR']\n","  X = df.drop(columns=['STAT_CAUSE_DESCR'])\n","  return X, y"]},{"cell_type":"markdown","source":["Result of Experiment: It makes the model perform worse."],"metadata":{"id":"lYSGE9lQVTGc"}},{"cell_type":"markdown","metadata":{"id":"ltkeVMGfwhR-"},"source":["# Preparation"]},{"cell_type":"markdown","source":["Now we will prepare the data for XGBoost. In the following function, we basically did all the things we said we have done in the above sections. This takes about 5 mins, since we ran DBSCAN and we have some encodings that takes time to perform."],"metadata":{"id":"WpEBjAP6VatK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0QQX81u4UpJp","ExecuteTime":{"end_time":"2024-04-28T05:38:29.996026Z","start_time":"2024-04-28T05:38:29.962638Z"},"executionInfo":{"status":"aborted","timestamp":1716473903323,"user_tz":-180,"elapsed":65,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["# select features for trainin: This list depends on feature engineering\n","encoded_catagorical_features = ['FE-' + feature for feature in catagorical_features]\n","encoded_null_features = ['NE-'+ feature for feature in null_features]\n","selected_features = encoded_catagorical_features + encoded_null_features + geospacial_features + ['FIRE_SIZE']+ encoded_time_data +['STORM']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bpCE3vJdIpP9","ExecuteTime":{"end_time":"2024-04-28T05:38:30.015564Z","start_time":"2024-04-28T05:38:29.964445Z"},"executionInfo":{"status":"aborted","timestamp":1716473903324,"user_tz":-180,"elapsed":66,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["def transform_data_for_XGB(X, y, train = False):\n","  # null encoding: notice: encode null first because we might do some imputation later.\n","  X = null_encoding(X)\n","\n","  # encode geospacial data\n","  if train==True:\n","    # train state encoding\n","    train_df = pd.concat([X, y], axis=1)\n","    train_state_encoders(train_df)\n","    #train clusters of coordinates\n","    train_target_class_clusters(train_df)\n","  X = encode_geospacial_data(X)\n","\n","  # encode time data\n","  X = time_encoding(X)\n","\n","  # add imputation\n","  if train==True:\n","    train_DELTA_TIME_IMPUTATOR(X)\n","  X = imputate_DELTA_TIME(X)\n","  X = imputate_COUNTY(X)\n","\n","\n","  if train==True:\n","    # train the frequency encoders\n","    train_frequency_encoders(X)\n","  # frequency encoding: notice: frequency encoding at the end!\n","  X = frequency_encoding(X)\n","\n","  # additional imforamtion: encode storm information: Notice: have to be after time encoding\n","  X = encode_storm_data(X)\n","\n","  # select feature for training\n","  X = X[selected_features]\n","\n","  # change \"object\" dtypes to \"category\" types\n","  catagorial_columns = X.select_dtypes('object').columns.tolist()\n","  for col in catagorial_columns:\n","    X = X.astype({col:'category'})\n","\n","  # encode y\n","  y = target_encoder.transform(y)\n","  return X, y\n"]},{"cell_type":"code","source":["train_df = X_train.copy()\n","train_df['STAT_CAUSE_DESCR'] = y_train\n","\n","train_df = drop_outliers(train_df)\n","y_drop_outliers = train_df['STAT_CAUSE_DESCR']\n","X_drop_outliers = train_df.drop('STAT_CAUSE_DESCR', axis=1)"],"metadata":{"id":"Fe239RQdvcq_","ExecuteTime":{"end_time":"2024-04-28T05:38:31.879614Z","start_time":"2024-04-28T05:38:29.971706Z"},"executionInfo":{"status":"aborted","timestamp":1716473903324,"user_tz":-180,"elapsed":66,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train_anomaly, y_train_anomaly = transform_data_for_XGB(X_drop_outliers, y_drop_outliers, train=True)"],"metadata":{"id":"zhek5tOWvfdF","ExecuteTime":{"end_time":"2024-04-28T05:39:33.947829Z","start_time":"2024-04-28T05:38:31.890791Z"},"executionInfo":{"status":"aborted","timestamp":1716473903325,"user_tz":-180,"elapsed":66,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nsf_4_6CMn0B","ExecuteTime":{"end_time":"2024-04-28T05:41:19.768039Z","start_time":"2024-04-28T05:39:33.952411Z"},"executionInfo":{"status":"aborted","timestamp":1716473903325,"user_tz":-180,"elapsed":66,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["X_train, y_train = transform_data_for_XGB(X_train, y_train, train=True)\n","X_val, y_val = transform_data_for_XGB(X_val, y_val)\n","X_test, y_test = transform_data_for_XGB(X_test, y_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OpD9tqzDRPos","ExecuteTime":{"end_time":"2024-04-28T05:41:20.183359Z","start_time":"2024-04-28T05:41:19.800943Z"},"executionInfo":{"status":"aborted","timestamp":1716473903325,"user_tz":-180,"elapsed":66,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["# save the files to drive, so that we can switch to GPU here\n","import pickle\n","def dump_file(obj, file_path):\n","  with open(file_path, 'wb') as f:\n","    pickle.dump(obj, f)\n","dump_file(X_train,'/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_train.csv')\n","dump_file(y_train,'/content/drive/MyDrive/Projects/FirePrediction/tempFiles/y_train.csv')\n","dump_file(X_val,'/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_val.csv')\n","dump_file(y_val, '/content/drive/MyDrive/Projects/FirePrediction/tempFiles/y_val.csv')\n","dump_file(target_encoder, '/content/drive/MyDrive/Projects/FirePrediction/tempFiles/target_encoder')\n","dump_file(X_test,'/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_test.csv')\n","dump_file(y_test,'/content/drive/MyDrive/Projects/FirePrediction/tempFiles/y_test.csv')\n","\n","dump_file(X_train_anomaly,'/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_train_anomaly.csv')\n","\n","dump_file(y_train_anomaly,'/content/drive/MyDrive/Projects/FirePrediction/tempFiles/y_train_anomaly.csv')\n"]},{"cell_type":"markdown","source":["Prepare data for Decision Tree, Random Forest and CatBoost"],"metadata":{"id":"ga8F2i4pBWlD"}},{"cell_type":"code","source":["from scipy.stats import entropy\n","train_df = X_train.copy()\n","train_df['STAT_CAUSE_DESCR'] = y_train\n","val_df = X_val.copy()\n","val_df['STAT_CAUSE_DESCR'] = y_val\n","\n","percentage_of_each_label = train_df['STAT_CAUSE_DESCR'].value_counts(normalize=True)\n","\n","def calculate_kl_divergence(row):\n","  kl_div = entropy(row, percentage_of_each_label)\n","  return kl_div\n","divergences_map = {}\n","def train_kl_encode(df, feature):\n","  # training only depends on train set\n","  cross_Vals = pd.crosstab(df[feature], df['STAT_CAUSE_DESCR'],  normalize='index')\n","  cross_Vals = cross_Vals.div(percentage_of_each_label, axis=1)\n","  global divergences_map\n","  divergences_map[feature] = cross_Vals.apply(calculate_kl_divergence, axis=1).to_dict()\n","\n","def encode_catagory_by_kl(df, feature):\n","  # encoding depends on df\n","  df[feature] = df[feature].map(divergences_map[feature])\n","  # Convert to numeric, coerce errors to NaN, else we cannot fillna(0)\n","  df[feature] = pd.to_numeric(df[feature], errors='coerce')\n","  df[feature] = df[feature].fillna(0)\n","  return df\n","train_kl_encode(train_df, 'MONTH')\n","train_kl_encode(train_df, 'DAY_OF_WEEK')\n","train_df = encode_catagory_by_kl(train_df, 'MONTH')\n","train_df = encode_catagory_by_kl(train_df, 'DAY_OF_WEEK')\n","val_df = encode_catagory_by_kl(val_df, 'MONTH')\n","val_df = encode_catagory_by_kl(val_df, 'DAY_OF_WEEK')\n","X_train['STORM'] = X_train['STORM'].astype(int)\n","X_train['independence_day'] = X_train['independence_day'].astype(int)\n","\n","# drop some columns\n","columns_to_drop = train_df.columns[train_df.isnull().any()]\n","# get null values from X_train, assume they are the same from X_val(We can't do drop any, might cause problem)\n","train_df = train_df.drop(columns=columns_to_drop)\n","val_df = val_df.drop(columns=columns_to_drop)\n","\n","# get X_train and X_val\n","X_train = train_df.drop(columns=['STAT_CAUSE_DESCR'])\n","X_val = val_df.drop(columns=['STAT_CAUSE_DESCR'])\n","\n","# convert back to normal\n","catagorial_columns = X_train.select_dtypes('category').columns.tolist()\n","for col in catagorial_columns:\n","  X_train = X_train.astype({col:'object'})\n","catagorial_columns = X_val.select_dtypes('category').columns.tolist()\n","for col in catagorial_columns:\n","  X_val = X_val.astype({col:'object'})"],"metadata":{"id":"aVAYoDqBBnlU","ExecuteTime":{"end_time":"2024-04-28T05:41:21.101262Z","start_time":"2024-04-28T05:41:20.189848Z"},"executionInfo":{"status":"aborted","timestamp":1716473903326,"user_tz":-180,"elapsed":67,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["columns_to_drop = train_df.columns[train_df.isnull().any()]\n","# get null values from X_train, assume they are the same from X_val(We can't do drop any, might cause problem)\n","train_df = train_df.drop(columns=columns_to_drop)\n","val_df = val_df.drop(columns=columns_to_drop)\n","\n","# get X_train and X_val\n","X_train = train_df.drop(columns=['STAT_CAUSE_DESCR'])\n","X_val = val_df.drop(columns=['STAT_CAUSE_DESCR'])\n","\n","# convert back to normal\n","catagorial_columns = X_train.select_dtypes('category').columns.tolist()\n","for col in catagorial_columns:\n","  X_train = X_train.astype({col:'object'})\n","catagorial_columns = X_val.select_dtypes('category').columns.tolist()\n","for col in catagorial_columns:\n","  X_val = X_val.astype({col:'object'})"],"metadata":{"id":"GiJg7sFbBgCA","ExecuteTime":{"end_time":"2024-04-28T05:41:21.507694Z","start_time":"2024-04-28T05:41:21.108211Z"},"executionInfo":{"status":"aborted","timestamp":1716473903326,"user_tz":-180,"elapsed":66,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dump_file(X_train,'/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_train_other_model.csv')\n","dump_file(y_train,'/content/drive/MyDrive/Projects/FirePrediction/tempFiles/y_train_other_model.csv')\n","dump_file(X_val,'/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_val_other_model.csv')\n","dump_file(y_val, '/content/drive/MyDrive/Projects/FirePrediction/tempFiles/y_val_other_model.csv')"],"metadata":{"id":"N-__LC62B0Ga","ExecuteTime":{"end_time":"2024-04-28T05:41:21.722226Z","start_time":"2024-04-28T05:41:21.508479Z"},"executionInfo":{"status":"aborted","timestamp":1716473903326,"user_tz":-180,"elapsed":66,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VrQy5S45l5Ft"},"source":["# Model Selection"]},{"cell_type":"markdown","source":["## XGBoost"],"metadata":{"id":"IcO3fm5VCEel"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2nxUH3EVmgBv","ExecuteTime":{"end_time":"2024-04-28T05:41:21.893928Z","start_time":"2024-04-28T05:41:21.724180Z"},"executionInfo":{"status":"aborted","timestamp":1716473903327,"user_tz":-180,"elapsed":67,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["import pandas as pd\n","import pickle\n","def load_file(file_path):\n","  with open(file_path, 'rb') as f:\n","    obj = pickle.load(f)\n","    return obj\n","X_train = load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_train.csv')\n","y_train= load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/y_train.csv')\n","X_val= load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_val.csv')\n","y_val= load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/y_val.csv')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YT7a8zA5PmyZ","ExecuteTime":{"end_time":"2024-04-28T05:43:43.929299Z","start_time":"2024-04-28T05:41:21.896623Z"},"executionInfo":{"status":"aborted","timestamp":1716473903327,"user_tz":-180,"elapsed":66,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["from xgboost import XGBClassifier\n","# define hyper parameters\n","params = {\n","    \"device\": \"cuda\",\n","    \"enable_categorical\": True,\n","     \"n_estimators\": 250,\n","}\n","# create model instance\n","clf = XGBClassifier(**params,)\n","# fit model\n","clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)])\n","# save the model\n","clf.save_model('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/xgb.json')\n"]},{"cell_type":"markdown","source":["## Decision Tree"],"metadata":{"id":"9mg8dsruOTRA"}},{"cell_type":"code","source":["import pandas as pd\n","import pickle\n","def load_file(file_path):\n","  with open(file_path, 'rb') as f:\n","    obj = pickle.load(f)\n","    return obj\n","X_train = load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_train_other_model.csv')\n","y_train = load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/y_train_other_model.csv')\n","X_val = load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_val_other_model.csv')\n","y_val = load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/y_val_other_model.csv')"],"metadata":{"id":"4t1UxnjOOzMf","ExecuteTime":{"end_time":"2024-04-28T05:43:44.111321Z","start_time":"2024-04-28T05:43:43.928843Z"},"executionInfo":{"status":"aborted","timestamp":1716473903328,"user_tz":-180,"elapsed":67,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","clf_DT = DecisionTreeClassifier()\n","clf_DT.fit(X_train, y_train)\n"],"metadata":{"id":"IY4KsJ3WC8OE","ExecuteTime":{"end_time":"2024-04-28T05:44:03.734806Z","start_time":"2024-04-28T05:43:44.111571Z"},"executionInfo":{"status":"aborted","timestamp":1716473903328,"user_tz":-180,"elapsed":67,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import joblib\n","joblib.dump(clf_DT, '/content/drive/MyDrive/Projects/FirePrediction/tempFiles/decisionTree.json')"],"metadata":{"id":"uRWoA3y-GsOQ","ExecuteTime":{"end_time":"2024-04-28T05:44:03.882960Z","start_time":"2024-04-28T05:44:03.731656Z"},"executionInfo":{"status":"aborted","timestamp":1716473903328,"user_tz":-180,"elapsed":66,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Random Forest"],"metadata":{"id":"7PpcDfZwCZZa"}},{"cell_type":"code","source":["import pandas as pd\n","import pickle\n","def load_file(file_path):\n","  with open(file_path, 'rb') as f:\n","    obj = pickle.load(f)\n","    return obj\n","X_train = load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_train_other_model.csv')\n","y_train = load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/y_train_other_model.csv')\n","X_val = load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_val_other_model.csv')\n","y_val = load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/y_val_other_model.csv')"],"metadata":{"id":"uIMwIWgFCzS9","ExecuteTime":{"end_time":"2024-04-28T05:44:04.010899Z","start_time":"2024-04-28T05:44:03.772924Z"},"executionInfo":{"status":"aborted","timestamp":1716473903329,"user_tz":-180,"elapsed":67,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","clf_RF = RandomForestClassifier(n_estimators=100, random_state=42)\n","clf_RF.fit(X_train, y_train)"],"metadata":{"id":"8tjQn6a0DE-w","ExecuteTime":{"end_time":"2024-04-28T05:46:33.190733Z","start_time":"2024-04-28T05:44:03.983395Z"},"executionInfo":{"status":"aborted","timestamp":1716473903329,"user_tz":-180,"elapsed":67,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import joblib\n","joblib.dump(clf_RF, '/content/drive/MyDrive/Projects/FirePrediction/tempFiles/randomForest.json')"],"metadata":{"id":"XgPdL5xiG__E","ExecuteTime":{"end_time":"2024-04-28T05:46:35.393755Z","start_time":"2024-04-28T05:46:33.187213Z"},"executionInfo":{"status":"aborted","timestamp":1716473903329,"user_tz":-180,"elapsed":67,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## CatBoost"],"metadata":{"id":"4IIPzx0tCbsi"}},{"cell_type":"code","source":["!pip install catboost"],"metadata":{"id":"g8sEYz0sEKgo","ExecuteTime":{"end_time":"2024-04-28T05:46:37.202813Z","start_time":"2024-04-28T05:46:35.444114Z"},"executionInfo":{"status":"aborted","timestamp":1716473903330,"user_tz":-180,"elapsed":67,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import pickle\n","def load_file(file_path):\n","  with open(file_path, 'rb') as f:\n","    obj = pickle.load(f)\n","    return obj\n","X_train = load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_train_other_model.csv')\n","y_train = load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/y_train_other_model.csv')\n","X_val = load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_val_other_model.csv')\n","y_val = load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/y_val_other_model.csv')"],"metadata":{"id":"iPr2kXY1C0T0","ExecuteTime":{"end_time":"2024-04-28T05:46:37.429380Z","start_time":"2024-04-28T05:46:37.222436Z"},"executionInfo":{"status":"aborted","timestamp":1716473903330,"user_tz":-180,"elapsed":67,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from catboost import CatBoostClassifier\n","clf_CB = CatBoostClassifier(verbose=False, task_type='GPU')\n","clf_CB.fit(X_train, y_train)\n","clf_CB.save_model('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/catboost.json')\n"],"metadata":{"id":"ORz1gzJwpZYv","ExecuteTime":{"end_time":"2024-04-28T05:58:02.409991Z","start_time":"2024-04-28T05:47:31.436141Z"},"executionInfo":{"status":"aborted","timestamp":1716473903330,"user_tz":-180,"elapsed":67,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CgnlG3Rviae1"},"source":["# Other attempts"]},{"cell_type":"markdown","source":["We did 300 iterations for each model and we see that for all model always converges afetr 250 iteration."],"metadata":{"id":"OuVD78evXqFZ"}},{"cell_type":"markdown","source":["Here we will show some of the significant attempts to improve the model. But we will explain in the Evaluation section their preformance."],"metadata":{"id":"b3zn7iSFWPAj"}},{"cell_type":"markdown","metadata":{"id":"t-pj-hqftXjs"},"source":["## Balancing data"]},{"cell_type":"code","source":["import pandas as pd\n","import pickle\n","def load_file(file_path):\n","  with open(file_path, 'rb') as f:\n","    obj = pickle.load(f)\n","    return obj\n","X_train = load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_train.csv')\n","y_train= load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/y_train.csv')\n","X_val= load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_val.csv')\n","y_val= load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/y_val.csv')\n"],"metadata":{"id":"UfAxes9EYHZa","ExecuteTime":{"end_time":"2024-04-28T05:58:02.997406Z","start_time":"2024-04-28T05:58:02.450164Z"},"executionInfo":{"status":"aborted","timestamp":1716473903331,"user_tz":-180,"elapsed":68,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","def calculate_sample_weights(y_train):\n","  class_counts = np.bincount(y_train)\n","  total_example = np.sum(class_counts)\n","  class_weights = total_example/(len(class_counts)* class_counts)\n","  sample_weights = class_weights[y_train]\n","  return sample_weights"],"metadata":{"id":"66pST9DQcowt","ExecuteTime":{"end_time":"2024-04-28T05:58:03.004755Z","start_time":"2024-04-28T05:58:02.998228Z"},"executionInfo":{"status":"aborted","timestamp":1716473903331,"user_tz":-180,"elapsed":67,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qjKFcqAlty7O","ExecuteTime":{"end_time":"2024-04-28T05:58:03.030872Z","start_time":"2024-04-28T05:58:03.001852Z"},"executionInfo":{"status":"aborted","timestamp":1716473903331,"user_tz":-180,"elapsed":67,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["sample_weights = calculate_sample_weights(y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6HF8vDnQtW5g","ExecuteTime":{"end_time":"2024-04-28T06:00:35.680319Z","start_time":"2024-04-28T05:58:03.012192Z"},"executionInfo":{"status":"aborted","timestamp":1716473903332,"user_tz":-180,"elapsed":68,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["from xgboost import XGBClassifier\n","\n","# define hyper parameters\n","params = {\n","    \"device\": \"cuda\",\n","    \"enable_categorical\": True,\n","     \"n_estimators\": 250\n","}\n","# create model instance\n","clf_balanced = XGBClassifier(**params,)\n","# fit model\n","clf_balanced.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)],sample_weight=sample_weights)\n","# save model\n","clf_balanced.save_model('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/xgb-balanced.json')"]},{"cell_type":"markdown","metadata":{"id":"DWrW70xELTpP"},"source":["## Anomaly Detection"]},{"cell_type":"code","source":["import pandas as pd\n","import pickle\n","def load_file(file_path):\n","  with open(file_path, 'rb') as f:\n","    obj = pickle.load(f)\n","    return obj\n","X_train = load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_train_anomaly.csv')\n","y_train= load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/y_train_anomaly.csv')\n","X_val= load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_val.csv')\n","y_val= load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/y_val.csv')\n"],"metadata":{"id":"7A9y1TlSi-MO","ExecuteTime":{"end_time":"2024-04-28T06:00:35.895956Z","start_time":"2024-04-28T06:00:35.694906Z"},"executionInfo":{"status":"aborted","timestamp":1716473903332,"user_tz":-180,"elapsed":69,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-gQteTc_MOS3","ExecuteTime":{"end_time":"2024-04-28T06:02:25.730324Z","start_time":"2024-04-28T06:00:35.897723Z"},"executionInfo":{"status":"aborted","timestamp":1716473903333,"user_tz":-180,"elapsed":68,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["from xgboost import XGBClassifier\n","\n","# define hyper parameters\n","params = {\n","    \"device\": \"cuda\",\n","    \"enable_categorical\": True,\n","     \"n_estimators\": 250,\n","}\n","# create model instance\n","clf_anomaly = XGBClassifier(**params,)\n","# fit model\n","clf_anomaly.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)])\n","# save model\n","clf_anomaly.save_model('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/xgb-anomaly.json')"]},{"cell_type":"markdown","metadata":{"id":"H14LEGDtgO8_"},"source":["## Feature Selection"]},{"cell_type":"markdown","metadata":{"id":"Tv8NHVvmgRed"},"source":["We will just run a simple feature selection here."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BKDv9VKP2DgS","ExecuteTime":{"end_time":"2024-04-28T06:02:25.890410Z","start_time":"2024-04-28T06:02:25.729971Z"},"executionInfo":{"status":"aborted","timestamp":1716473903333,"user_tz":-180,"elapsed":68,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["import pandas as pd\n","import pickle\n","def load_file(file_path):\n","  with open(file_path, 'rb') as f:\n","    obj = pickle.load(f)\n","    return obj\n","X_train = load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_train.csv')\n","y_train= load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/y_train.csv')\n","X_val= load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_val.csv')\n","y_val= load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/y_val.csv')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NDSFcR7egVr5","ExecuteTime":{"end_time":"2024-04-28T06:02:26.292988Z","start_time":"2024-04-28T06:02:25.891470Z"},"executionInfo":{"status":"aborted","timestamp":1716473903334,"user_tz":-180,"elapsed":69,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["from xgboost import XGBClassifier\n","\n","clf = XGBClassifier()\n","clf.load_model('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/xgb.json')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"azPzVICF1kgK","ExecuteTime":{"end_time":"2024-04-28T06:02:26.312522Z","start_time":"2024-04-28T06:02:26.299138Z"},"executionInfo":{"status":"aborted","timestamp":1716473903334,"user_tz":-180,"elapsed":68,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["import numpy as np\n","# Get feature importances\n","feature_importances = clf.feature_importances_\n","\n","# Sort features based on importance\n","sorted_idx = np.argsort(feature_importances)[::-1]\n","\n","# let's look at what features are more importamt\n","column_names = [X_train.columns[i] for i in sorted_idx]\n","column_names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UIdbmeJBgiTT","ExecuteTime":{"end_time":"2024-04-28T06:02:26.432747Z","start_time":"2024-04-28T06:02:26.311454Z"},"executionInfo":{"status":"aborted","timestamp":1716473903335,"user_tz":-180,"elapsed":69,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["# Select top 30 out of 75 features\n","top_n_features = sorted_idx[:30]\n","X_train_feature = X_train.iloc[:, top_n_features]\n","X_val_feature = X_val.iloc[:, top_n_features]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4U38B4OY6N_0","ExecuteTime":{"end_time":"2024-04-28T06:02:26.629643Z","start_time":"2024-04-28T06:02:26.397915Z"},"executionInfo":{"status":"aborted","timestamp":1716473903336,"user_tz":-180,"elapsed":69,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["import pickle\n","def dump_file(obj, file_path):\n","  with open(file_path, 'wb') as f:\n","    pickle.dump(obj, f)\n","dump_file(X_train_feature,'/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_train_feature.csv')\n","dump_file(X_val_feature,'/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_val_feature.csv')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wUY3jA7LhQIF","ExecuteTime":{"end_time":"2024-04-28T06:03:20.302837Z","start_time":"2024-04-28T06:02:26.621825Z"},"executionInfo":{"status":"aborted","timestamp":1716473903336,"user_tz":-180,"elapsed":69,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["from xgboost import XGBClassifier\n","\n","# define hyper parameters\n","params = {\n","    \"device\": \"cuda\",\n","    \"enable_categorical\": True,\n","     \"n_estimators\": 250,\n","}\n","# create model instance\n","clf_feature = XGBClassifier(**params,)\n","# fit model\n","clf_feature.fit(X_train_feature, y_train, eval_set=[(X_train_feature, y_train), (X_val_feature, y_val)])\n","# save the model\n","clf_feature.save_model('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/xgb-feature.json')\n"]},{"cell_type":"markdown","metadata":{"id":"vBLV539TQgr8"},"source":["# Evaluation XGBoost"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BOIAzpinzOwe","ExecuteTime":{"end_time":"2024-04-28T06:03:20.508301Z","start_time":"2024-04-28T06:03:20.287740Z"},"executionInfo":{"status":"aborted","timestamp":1716473903336,"user_tz":-180,"elapsed":69,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["import pandas as pd\n","import pickle\n","def load_file(file_path):\n","  with open(file_path, 'rb') as f:\n","    obj = pickle.load(f)\n","    return obj\n","X_train = load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_train.csv')\n","y_train= load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/y_train.csv')\n","X_val= load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_val.csv')\n","y_val= load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/y_val.csv')\n","target_encoder = load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/target_encoder')\n","X_test= load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_test.csv')\n","y_test =load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/y_test.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rXDiCGnfQrFt","ExecuteTime":{"end_time":"2024-04-28T06:03:20.516659Z","start_time":"2024-04-28T06:03:20.511894Z"},"executionInfo":{"status":"aborted","timestamp":1716473903337,"user_tz":-180,"elapsed":69,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["import numpy as np\n","from sklearn.preprocessing import LabelBinarizer\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import roc_curve, auc\n","\n","# Function that will print the preformance for each class\n","def plot_auc_by_class(y_val, y_pred_prob, ovr_auc, model_name):\n","  fpr = dict()\n","  tpr = dict()\n","  roc_auc = dict()\n","  label_binarizer = LabelBinarizer()\n","\n","  for i in range(y_pred_prob.shape[1]):\n","    y_true_class = label_binarizer.fit_transform(y_val == i)\n","    # Calculate ROC curve and AUC for the current class\n","    fpr[i], tpr[i], _ = roc_curve(y_true_class[:, 0], y_pred_prob[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","  # Plot ROC curves for each class\n","  plt.figure(figsize=(10, 8))\n","\n","  for i in range(y_pred_prob.shape[1]):\n","      class_name = target_encoder.inverse_transform([i])[0]\n","      plt.plot(fpr[i], tpr[i], label=f'{class_name} (AUC = {roc_auc[i]:.2f})')\n","  plt.plot([0, 1], [0, 1], 'k--', lw=2)  # Plot diagonal line for reference\n","  plt.xlabel('False Positive Rate')\n","  plt.ylabel('True Positive Rate')\n","  plt.title(f'ROC Curve for Each Class (Score: {ovr_auc}, model: {model_name})')\n","  plt.legend(loc='lower right')\n","  plt.show()"]},{"cell_type":"markdown","source":["## XGBoost - logloss"],"metadata":{"id":"yv3MT5giJP8u"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WzZ848abQkSE","ExecuteTime":{"end_time":"2024-04-28T06:03:23.712207Z","start_time":"2024-04-28T06:03:20.514261Z"},"executionInfo":{"status":"aborted","timestamp":1716473903337,"user_tz":-180,"elapsed":69,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["from sklearn.metrics import roc_auc_score\n","from xgboost import XGBClassifier\n","\n","clf = XGBClassifier()\n","clf.load_model('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/xgb.json')\n","\n","y_pred_prob = clf.predict_proba(X_val)  # proba of positive samples\n","ovr_auc = roc_auc_score(y_val, y_pred_prob, multi_class='ovr',average=\"weighted\")\n","ovr_auc"]},{"cell_type":"code","source":["plot_auc_by_class(y_val, y_pred_prob, ovr_auc, 'XGB-logloss')"],"metadata":{"id":"s_Gs7PJucoZR","ExecuteTime":{"end_time":"2024-04-28T06:03:24.205534Z","start_time":"2024-04-28T06:03:23.706830Z"},"executionInfo":{"status":"aborted","timestamp":1716473903337,"user_tz":-180,"elapsed":69,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k4bL_o-xoFhY","ExecuteTime":{"end_time":"2024-04-28T06:03:27.066896Z","start_time":"2024-04-28T06:03:24.213911Z"},"executionInfo":{"status":"aborted","timestamp":1716473903338,"user_tz":-180,"elapsed":69,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["from sklearn.metrics import ConfusionMatrixDisplay\n","ConfusionMatrixDisplay.from_predictions(clf.predict(X_val),y_val, normalize='true')"]},{"cell_type":"markdown","source":["## XGBoost - Balanced"],"metadata":{"id":"7WelUZMqJWIy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vw9BGg-MuaOn","ExecuteTime":{"end_time":"2024-04-28T06:03:30.190505Z","start_time":"2024-04-28T06:03:27.069089Z"},"executionInfo":{"status":"aborted","timestamp":1716473903338,"user_tz":-180,"elapsed":69,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["clf = XGBClassifier()\n","clf.load_model('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/xgb-balanced.json')\n","y_pred_prob = clf.predict_proba(X_val)  # proba of positive samples\n","ovr_auc = roc_auc_score(y_val, y_pred_prob, multi_class='ovr',average=\"weighted\")\n","ovr_auc"]},{"cell_type":"code","source":["plot_auc_by_class(y_val, y_pred_prob, ovr_auc, 'XGB-logloss-balanced')"],"metadata":{"id":"kipnXtqDcvI5","ExecuteTime":{"end_time":"2024-04-28T06:03:30.577438Z","start_time":"2024-04-28T06:03:30.186626Z"},"executionInfo":{"status":"aborted","timestamp":1716473903338,"user_tz":-180,"elapsed":69,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## XGBoost - anomaly"],"metadata":{"id":"2FoZ97NWJcZl"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"L1SYv444NJCv","ExecuteTime":{"end_time":"2024-04-28T06:03:33.734058Z","start_time":"2024-04-28T06:03:30.578196Z"},"executionInfo":{"status":"aborted","timestamp":1716473903339,"user_tz":-180,"elapsed":70,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["from sklearn.metrics import roc_auc_score\n","from xgboost import XGBClassifier\n","\n","clf = XGBClassifier()\n","clf.load_model('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/xgb-anomaly.json')\n","y_pred_prob = clf.predict_proba(X_val)  # proba of positive samples\n","ovr_auc = roc_auc_score(y_val, y_pred_prob, multi_class='ovr',average=\"weighted\")\n","ovr_auc"]},{"cell_type":"code","source":["plot_auc_by_class(y_val, y_pred_prob, ovr_auc, 'XGB-anomaly')"],"metadata":{"id":"2z5d-9YFcwun","ExecuteTime":{"end_time":"2024-04-28T06:03:34.112Z","start_time":"2024-04-28T06:03:33.729778Z"},"executionInfo":{"status":"aborted","timestamp":1716473903339,"user_tz":-180,"elapsed":69,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## XGBoost feature selection"],"metadata":{"id":"J2DKRsi_Jgh8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kH9Yz3r75K8Z","ExecuteTime":{"end_time":"2024-04-28T06:03:36.557760Z","start_time":"2024-04-28T06:03:34.113086Z"},"executionInfo":{"status":"aborted","timestamp":1716473903339,"user_tz":-180,"elapsed":69,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"outputs":[],"source":["clf = XGBClassifier()\n","clf.load_model('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/xgb-feature.json')\n","\n","X_train = load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_train_feature.csv')\n","X_val= load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_val_feature.csv')\n","\n","y_pred_prob = clf.predict_proba(X_val)  # proba of positive samples\n","ovr_auc = roc_auc_score(y_val, y_pred_prob, multi_class='ovr',average=\"weighted\")\n","ovr_auc"]},{"cell_type":"code","source":["plot_auc_by_class(y_val, y_pred_prob, ovr_auc, 'XGB-logloss-feature')"],"metadata":{"id":"1dMF1Eg2cyof","ExecuteTime":{"end_time":"2024-04-28T06:03:36.935241Z","start_time":"2024-04-28T06:03:36.553984Z"},"executionInfo":{"status":"aborted","timestamp":1716473903340,"user_tz":-180,"elapsed":70,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## CatBoost"],"metadata":{"id":"hKf_EeD_JlPf"}},{"cell_type":"code","source":["import pandas as pd\n","import pickle\n","def load_file(file_path):\n","  with open(file_path, 'rb') as f:\n","    obj = pickle.load(f)\n","    return obj\n","X_train = load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_train_other_model.csv')\n","y_train = load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/y_train_other_model.csv')\n","X_val = load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/X_val_other_model.csv')\n","y_val = load_file('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/y_val_other_model.csv')"],"metadata":{"id":"rMgjbWE4E9ng","ExecuteTime":{"end_time":"2024-04-28T06:03:37.123950Z","start_time":"2024-04-28T06:03:36.935133Z"},"executionInfo":{"status":"aborted","timestamp":1716473903340,"user_tz":-180,"elapsed":70,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install catboost"],"metadata":{"id":"sL5QnvNbFCLr","ExecuteTime":{"end_time":"2024-04-28T06:03:38.320588Z","start_time":"2024-04-28T06:03:37.107111Z"},"executionInfo":{"status":"aborted","timestamp":1716473903340,"user_tz":-180,"elapsed":69,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from catboost import CatBoostClassifier\n","\n","# Load the CatBoost model from a file\n","clf = CatBoostClassifier()\n","clf.load_model('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/catboost.json')"],"metadata":{"id":"UlmaTmIoEsGZ","ExecuteTime":{"end_time":"2024-04-28T06:03:38.371386Z","start_time":"2024-04-28T06:03:38.323622Z"},"executionInfo":{"status":"aborted","timestamp":1716473903341,"user_tz":-180,"elapsed":70,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import roc_auc_score\n","\n","y_pred_prob = clf.predict_proba(X_val)  # proba of positive samples\n","ovr_auc = roc_auc_score(y_val, y_pred_prob, multi_class='ovr',average=\"weighted\")\n","plot_auc_by_class(y_val, y_pred_prob, ovr_auc, 'catboost')"],"metadata":{"id":"Thpb1GlkE4ql","ExecuteTime":{"end_time":"2024-04-28T06:03:39.223592Z","start_time":"2024-04-28T06:03:38.382394Z"},"executionInfo":{"status":"aborted","timestamp":1716473903341,"user_tz":-180,"elapsed":70,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Decision Tree"],"metadata":{"id":"viCQHhRTJoZi"}},{"cell_type":"code","source":["import joblib\n","\n","# Load the model from a file\n","clf = joblib.load('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/decisionTree.json')\n","from sklearn.metrics import roc_auc_score\n","y_pred_prob = clf.predict_proba(X_val)  # proba of positive samples\n","ovr_auc = roc_auc_score(y_val, y_pred_prob, multi_class='ovr',average=\"weighted\")\n","plot_auc_by_class(y_val, y_pred_prob, ovr_auc, 'Decision Tree')"],"metadata":{"id":"stfjtIcoHSEo","ExecuteTime":{"end_time":"2024-04-28T06:03:39.724227Z","start_time":"2024-04-28T06:03:39.220160Z"},"executionInfo":{"status":"aborted","timestamp":1716473903342,"user_tz":-180,"elapsed":71,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Random Forest"],"metadata":{"id":"QsAQr3-_Jqyr"}},{"cell_type":"code","source":["import joblib\n","\n","# Load the model from a file\n","clf = joblib.load('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/randomForest.json')\n","from sklearn.metrics import roc_auc_score\n","\n","y_pred_prob = clf.predict_proba(X_val)  # proba of positive samples\n","ovr_auc = roc_auc_score(y_val, y_pred_prob, multi_class='ovr',average=\"weighted\")\n","plot_auc_by_class(y_val, y_pred_prob, ovr_auc, 'Random Forest')"],"metadata":{"id":"NmJRsj_sHTFv","ExecuteTime":{"end_time":"2024-04-28T06:03:46.131391Z","start_time":"2024-04-28T06:03:39.712185Z"},"executionInfo":{"status":"aborted","timestamp":1716473903342,"user_tz":-180,"elapsed":70,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Final evaluation"],"metadata":{"id":"rsNyYc_lmrhG"}},{"cell_type":"markdown","source":["Lastly, we will test the best model on our untouched test data:"],"metadata":{"id":"lmU9UF18mtbf"}},{"cell_type":"code","source":["from sklearn.metrics import roc_auc_score\n","from xgboost import XGBClassifier\n","\n","clf = XGBClassifier()\n","clf.load_model('/content/drive/MyDrive/Projects/FirePrediction/tempFiles/xgb.json')\n","\n","y_pred_prob = clf.predict_proba(X_test)  # proba of positive samples\n","ovr_auc = roc_auc_score(y_test, y_pred_prob, multi_class='ovr',average=\"weighted\")\n","ovr_auc"],"metadata":{"id":"ipivKQO4myGM","ExecuteTime":{"end_time":"2024-04-28T06:03:49.278218Z","start_time":"2024-04-28T06:03:46.232500Z"},"executionInfo":{"status":"aborted","timestamp":1716473903342,"user_tz":-180,"elapsed":70,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_auc_by_class(y_test, y_pred_prob, ovr_auc, 'XGB-logloss)(TEST')"],"metadata":{"id":"vfTGT6amnT0h","ExecuteTime":{"end_time":"2024-04-28T06:03:49.651963Z","start_time":"2024-04-28T06:03:49.278560Z"},"executionInfo":{"status":"aborted","timestamp":1716473903343,"user_tz":-180,"elapsed":71,"user":{"displayName":"Shkitan Levy","userId":"09808061690941854349"}}},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["H14LEGDtgO8_"],"toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}